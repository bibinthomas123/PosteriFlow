# Distribution Metrics - Quick Reference Card

## ğŸ¯ The 5 Metrics at a Glance

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ METRIC         â”‚ FORMULA                   â”‚ RANGE   â”‚ GOOD      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ AUC            â”‚ ROC Area Under Curve      â”‚ [0, 1]  â”‚ > 0.75    â”‚
â”‚ Entropy        â”‚ -Î£(p * log(p))           â”‚ [0, âˆ]  â”‚ < 1.5     â”‚
â”‚ Sharpness      â”‚ 1/(1 + smoothness)       â”‚ [0, 1]  â”‚ > 0.85    â”‚
â”‚ Wasserstein    â”‚ Optimal Transport Dist   â”‚ [0, 1]  â”‚ > 0.15    â”‚
â”‚ KL Divergence  â”‚ Î£(p * log(p/q))          â”‚ [0, âˆ]  â”‚ > 0.5     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Where They Are

| File | Location | Usage |
|------|----------|-------|
| `tests/test_priority_net.py` | Lines 17-80 | Unit tests (12 test functions) |
| `experiments/test_priority_net.py` | Lines 18-80 | Stress test validation |

## ğŸš€ Quick Start

### Run Unit Tests
```bash
pytest tests/test_priority_net.py -k "distribution" -v
```

### Use in Validation
```bash
python experiments/test_priority_net.py \
  --model models/priority_net/priority_net_best.pth \
  --data_dir data/output \
  --device cpu
```

### Import in Your Code
```python
from tests.test_priority_net import DistributionMetrics
# or
from experiments.test_priority_net import DistributionMetrics

# Use any metric
auc = DistributionMetrics.compute_separation_auc(high_scores, low_scores)
entropy = DistributionMetrics.compute_entropy(predictions)
sharpness = DistributionMetrics.compute_sharpness(predictions)
wasserstein = DistributionMetrics.compute_wasserstein_distance(s1, s2)
kl = DistributionMetrics.compute_kl_divergence(hist1, hist2)
```

## ğŸ’¡ Interpretation Guide

### Metric-by-Metric

**AUC** - How well does the model separate high vs low priority?
- 1.0 = Perfect separation (best case)
- 0.75 = Good discrimination (acceptable)
- 0.5 = Random guessing (unacceptable)

**Entropy** - Is the distribution sharp or blurry?
- Low (<1.5) = Sharp, decisive predictions âœ“
- High (>2.5) = Blurry, uncertain predictions âœ—

**Sharpness** - How confident are predictions?
- 0.9+ = Very decisive âœ“âœ“
- 0.7-0.9 = Good decisiveness âœ“
- <0.5 = Too uncertain âœ—

**Wasserstein** - How separated are the distributions?
- >0.5 = Very well separated âœ“âœ“
- 0.15-0.5 = Well separated âœ“
- <0.1 = Barely separated âœ—

**KL Divergence** - How different are the distributions?
- >2.0 = Very different âœ“âœ“
- 0.5-2.0 = Clearly different âœ“
- <0.1 = Too similar âœ—

## ğŸ“Š Expected Output Example

```
================================================================================
5ï¸âƒ£DistSep DISTRIBUTION SEPARATION & SHARPNESS
================================================================================
ğŸ¯ AUC (High vs Low SNR separation): 0.8234
ğŸ“Š Entropy (Lower = Sharper):
   High SNR: 0.7823
   Low SNR:  1.2456
   All:      0.9832
âš¡ Sharpness (Higher = More Decisive):
   High SNR: 0.8945
   Low SNR:  0.6234
   All:      0.7582
ğŸ“ Wasserstein Distance (High vs Low): 0.2456
ğŸ”€ KL Divergence (High vs Low): 2.3456

ğŸ“ˆ Statistical Summary:
   High SNR mean=0.782 std=0.087
   Low SNR  mean=0.345 std=0.156
   All      mean=0.564 std=0.213
   Range: [0.001, 0.998]
```

## âš ï¸ Red Flags

| Flag | Meaning | Fix |
|------|---------|-----|
| AUC < 0.65 | Poor SNR separation | Retrain, increase ranking weight |
| Entropy_high â‰ˆ Entropy_low | No distinction | Model under-training |
| Sharpness < 0.5 | Very uncertain | Increase calibration loss |
| Wasserstein < 0.05 | Distributions overlap too much | Improve feature engineering |
| KL < 0.1 | Distributions indistinguishable | Strong signal that model is failing |

## ğŸ”§ Configuration

All metrics are in `DistributionMetrics` class with static methods:

```python
# High SNR threshold
if snr > 18.0:  # Line 291 in test_priority_net.py
    high_snr_preds.append(pred)

# Low SNR threshold  
elif snr < 10.0:  # Line 293
    low_snr_preds.append(pred)
```

Modify these lines if you want different SNR cutoffs.

## ğŸ“š API Reference

```python
# Binary classification AUC (1.0 = perfect separation)
auc = DistributionMetrics.compute_separation_auc(
    high_priority_scores,  # np.array
    low_priority_scores    # np.array
)

# Shannon entropy of distribution (low = sharp, high = blurry)
entropy = DistributionMetrics.compute_entropy(
    probabilities  # np.array of [0, 1] values
)

# Sharpness as inverse of smoothness (1.0 = max sharp)
sharpness = DistributionMetrics.compute_sharpness(
    scores,        # np.array
    window_size=5  # default moving average window
)

# Wasserstein/Earth-Mover distance between distributions
distance = DistributionMetrics.compute_wasserstein_distance(
    scores1,  # np.array
    scores2   # np.array
)

# KL divergence (information-theoretic distance)
kl_div = DistributionMetrics.compute_kl_divergence(
    dist1,  # np.array (histogram counts)
    dist2   # np.array (histogram counts)
)
```

## ğŸ§ª Testing

All 12 tests in `tests/test_priority_net.py`:

```
âœ“ test_distribution_separation_auc
âœ“ test_distribution_separation_auc_overlapping
âœ“ test_distribution_separation_auc_poor
âœ“ test_entropy_sharp_distribution
âœ“ test_entropy_uniform_distribution
âœ“ test_sharpness_metric
âœ“ test_kl_divergence_identical_distributions
âœ“ test_kl_divergence_different_distributions
âœ“ test_wasserstein_distance
âœ“ test_wasserstein_distance_similar
âœ“ test_priority_net_separation_quality
âœ“ test_distribution_metrics_batch_consistency
âœ“ test_entropy_sharpness_correlation
```

All **PASSING** âœ…

## ğŸ“ Theory

- **AUC**: Receiver Operating Characteristic (Fawcett, 2006)
- **Entropy**: Shannon Information Theory (Shannon, 1948)
- **Sharpness**: Variance-based decisiveness measure
- **Wasserstein**: Optimal Transport Theory (Monge, 1781; Kantorovich, 1942)
- **KL Divergence**: Information-theoretic distance (Kullback & Leibler, 1951)

---

**Status**: Production Ready âœ… | **Tests**: 12/12 Passing | **Coverage**: Comprehensive
