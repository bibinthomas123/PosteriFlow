# AHSD Gravitational Wave Dataset & Generation Module

**Adaptive Hierarchical Signal Decomposition (AHSD) - Production-Scale Dataset Generator and 50k Benchmark Dataset**

A comprehensive toolkit for generating realistic gravitational wave datasets with overlapping signals, designed for AHSD pipeline development, validation, and publication-quality research.

---

## üìã Table of Contents

1. [Overview](#overview)
2. [Dataset Statistics (50k Benchmark)](#dataset-statistics-50k-benchmark)
3. [Features](#features)
4. [Installation](#installation)
5. [Quick Start](#quick-start)
6. [Generation Methodology](#generation-methodology)
7. [Dataset Composition](#dataset-composition)
8. [Edge Cases (20 Types)](#edge-cases-20-types)
9. [Extreme Cases (10 Types)](#extreme-cases-10-types)
10. [SNR Distribution](#snr-distribution)
11. [Module Structure](#module-structure)
12. [Usage Examples](#usage-examples)
13. [Configuration](#configuration)
14. [Dataset Format](#dataset-format)
15. [File Structure](#file-structure)
16. [API Reference](#api-reference)
17. [Validation](#validation)
18. [Citation](#citation)
19. [License & Support](#license--support)

---

## Overview

### Purpose

The AHSD system provides both a **flexible generation module** and a **production-ready 50,000-sample benchmark dataset** for training and evaluating machine learning models for gravitational wave detection and parameter estimation in overlapping signal scenarios. This addresses the critical challenge of detecting and characterizing multiple gravitational wave signals occurring simultaneously or in close temporal proximity.

### Key Highlights

- **Production Dataset:** 50,000 samples with 90,990 gravitational wave signals
- **Generation Time:** 9.4 hours at 1.47 samples/second
- **Detectors:** 3-detector network (LIGO Hanford H1, LIGO Livingston L1, Virgo V1)
- **Edge Cases:** 7,886 samples (15.8%) covering 20 challenging scenario types
- **Extreme Cases:** 1,001 samples (2.0%) covering 10 publication-critical cases
- **Astrophysical Realism:** GWTC-3 validated distributions
- **Publication Ready:** Suitable for Physical Review D, ApJ, or top-tier journals

---

## Dataset Statistics (50k Benchmark)

### Overall Composition

| Category | Count | Percentage | Total Signals | Description |
|----------|-------|------------|---------------|-------------|
| **Total Samples** | 50,000 | 100.0% | 90,990 | Complete dataset |
| **Single Events** | 23,010 | 46.0% | 23,010 | Non-overlapping signals |
| **Overlapping Events** | 26,990 | 54.0% | 67,980 | Multiple concurrent signals |
| **Edge Cases** | 7,886 | 15.8% | - | Challenging scenarios (20 types) |
| **Extreme Cases** | 1,001 | 2.0% | - | Publication-critical (10 types) |

### Event Type Distribution

| Event Type | Count | Percentage | Mass Range (M‚òâ) | Distance Range (Mpc) |
|------------|-------|------------|-----------------|----------------------|
| **BBH** | 11,026 | 22.1% | 5-100 | 50-3000 |
| **BNS** | 6,631 | 13.3% | 1-3 | 50-500 |
| **NSBH** | 4,771 | 9.5% | Mixed | 50-2000 |
| **Noise Only** | 582 | 1.2% | N/A | N/A |

### SNR Distribution (90,990 signals)

| SNR Regime | Range | Count | Actual % | Expected % | Status |
|------------|-------|-------|----------|------------|--------|
| **Weak** | 8-10 | 13,616 | 15.0% | 15% | ‚úÖ Perfect |
| **Low** | 10-15 | 36,062 | 39.6% | 35% | ‚úÖ Good |
| **Medium** | 15-25 | 30,340 | 33.3% | 30% | ‚úÖ Good |
| **High** | 25-40 | 8,633 | 9.5% | 15% | ‚ö†Ô∏è Acceptable |
| **Loud** | 40+ | 2,339 | 2.6% | 5% | ‚úì Good |

**Mean SNR:** 16.8 | **SNR Range:** 8.0 - 50.0

### Dataset Splits

| Split | Samples | Percentage | Purpose |
|-------|---------|------------|---------|
| **Training** | 39,997 | 80.0% | Model training |
| **Validation** | 4,999 | 10.0% | Hyperparameter tuning |
| **Test** | 5,004 | 10.0% | Final evaluation |

***

## Features

### Core Capabilities

- **Realistic Signal Generation**: BBH, BNS, and NSBH waveforms with PyCBC and analytical fallbacks
- **Overlapping Scenarios**: 2-5 simultaneous signals with configurable temporal separations (0.1-4.0 seconds)
- **GWTC Integration**: Compatible with real gravitational wave events from GWTC-3/GWTC-4
- **Astrophysical Realism**: 
  - Independent mass/distance sampling (decorrelated parameters)
  - Realistic tidal effects for BNS/NSBH
  - Spin-precession support (œá_p up to 0.99)
  - Cosmological redshift corrections (Planck 2018 cosmology)
  - Eccentric orbits (e up to 0.8)

### Advanced Noise Modeling

- **Colored Gaussian Noise**: Generated from Advanced LIGO/Virgo Design PSDs
- **Realistic Glitches**: Blip, Whistle, Koi Fish glitches (30% occurrence rate)
- **Non-Stationary Effects**: PSD drift, detector dropouts
- **Spectral Lines**: Calibration lines, violin modes

### Edge Case Coverage (20 Types)

#### Physical Extremes (8 types)
- High mass ratio (q < 0.1)
- Extreme spins (|a| > 0.95)
- Eccentric mergers (e > 0.3)
- Precessing systems (œá_p > 0.5)
- Short duration high mass (M > 100 M‚òâ)
- Low SNR threshold (œÅ ‚àà )[11][12]
- Extreme mass ratio (q < 0.05)
- Cosmological distance (z > 0.5)

#### Observational Extremes (4 types)
- Strong glitches (overlapping with signals)
- Detector dropouts (1-2 active detectors)
- PSD drift (20-50% variation)
- Sky position extremes (|Dec| > 75¬∞)

#### Statistical Extremes (3 types)
- Multimodal posteriors
- Heavy-tailed regions
- Uninformative priors

#### Overlap Extremes (5 types)
- Subtle ranking (ŒîSNR < 3)
- Heavy overlaps (3-5 signals)
- Partial overlaps (Œît ‚àà  s)
- Near-simultaneous mergers (Œît < 0.2 s)
- Weak-strong overlaps

### Extreme Case Coverage (10 Types)

Publication-critical scenarios (1,001 samples, 2.0%):
1. Near-simultaneous mergers (157) - Œît < 200 ms
2. Extreme mass ratio inspirals (145) - q < 0.05
3. High-spin aligned/anti-aligned (104) - |œá_eff| > 0.9
4. Precession-dominated (85) - œá_p > 0.8
5. Eccentric overlaps (97) - e > 0.3 for ‚â•2 signals
6. Weak-strong overlaps (92) - SNR contrast > 4:1
7. Noise-confused overlaps (92) - Signals + glitches
8. Long-duration BNS overlaps (52) - Combined duration > 60s
9. Detector dropouts (125) - Mid-signal detector loss
10. Cosmological distance (52) - d_L > 2000 Mpc

### Technical Features

- **Multi-detector Support**: H1, L1, V1 with realistic antenna patterns
- **Flexible I/O**: HDF5, pickle, JSON formats with batch processing
- **Preprocessing Pipeline**: Whitening, bandpass filtering  Hz, edge tapering[3]
- **Scalability**: Memory-optimized generation (safe for 32 GB RAM), parallel processing
- **Reproducibility**: Complete parameter logging, random seed control, auto-resume capability
- **Quality Control**: Strict SNR validation, automated data quality checks, comprehensive metadata

***

## Installation

### Prerequisites

```bash
python >= 3.8
numpy >= 1.24.0
scipy >= 1.10.0
```

### Install from source

```bash
# Clone the repository
git clone https://github.com/bibinthomas123/PosteriFlow.git
cd PosteriFlow

# Install with data generation dependencies
pip install -e .

# Or with all dependencies
pip install -e .[all]
```

### Install PyCBC (required for high-fidelity waveforms)

```bash
# Via conda (recommended)
conda install -c conda-forge pycbc lalsuite

# Or via pip
pip install pycbc lalsuite
```

### Optional: GWpy for real data access

```bash
pip install gwpy
```

***

## Quick Start

### Generate a Simple Dataset

```python
from ahsd.data import GWDatasetGenerator

# Initialize generator
generator = GWDatasetGenerator(
    output_dir="data/my_dataset",
    sample_rate=4096,
    duration=4.0,
    detectors=['H1', 'L1', 'V1']
)

# Generate 1000 samples
summary = generator.generate_dataset(
    n_samples=1000,
    overlap_fraction=0.5,      # 50% overlapping signals
    edge_case_fraction=0.15,   # 15% edge cases
    save_batch_size=100,
    add_glitches=True,
    preprocess=True
)

print(f"Dataset generated: {summary['output_dir']}")
print(f"Generation time: {summary['elapsed_time']:.1f}s")
print(f"Samples per second: {summary['samples_per_second']:.2f}")
```

### Command-Line Usage

```bash
# Generate production dataset (50k samples)
ahsd-generate \
    --config configs/data_config.yaml \
    --n-samples 50000 \
    --output-dir data/ahsd_overlaps \
    --overlap-fraction 0.5 \
    --edge-case-fraction 0.15 \
    --detectors H1 L1 V1 \
    --add-glitches \
    --preprocess

# Validate generated dataset
ahsd-validate --dataset-dir data/ahsd_overlaps

# Analyze dataset statistics
python -m ahsd.data.scripts.analyze_dataset \
    --dataset-dir data/ahsd_overlaps \
    --output-json dataset_stats.json
```

### Load and Inspect Dataset

```python
from ahsd.data.io_utils import DatasetReader

reader = DatasetReader()

# Load batch
batch = reader.load_pkl("data/my_dataset/train/chunk_0000.pkl")

print(f"Batch contains {len(batch)} samples")
print(f"First sample ID: {batch[0]['id']}")
print(f"Event type: {batch[0]['type']}")
print(f"N signals: {batch[0]['n_signals']}")
print(f"Edge case: {batch[0].get('edge_case_type', 'None')}")

# Access strain data
h1_strain = batch[0]['detector_data']['H1']['strain']
print(f"H1 strain shape: {h1_strain.shape}")  # (8192,)
```

***

## Generation Methodology

### 1. Waveform Generation

**Physics Engine:** PyCBC 2.3 + LALSuite 7.5

**Approximants:**
- **BBH:** IMRPhenomD, IMRPhenomPv2 (precessing), SEOBNRv4
- **BNS:** TaylorF2, IMRPhenomD_NRTidalv2 (tidal effects)
- **NSBH:** IMRPhenomD, SEOBNRv4_ROM, IMRPhenomNSBH

**Parameter Sampling Strategy:**

```python
# Mass distributions (component masses in M‚òâ)
BBH:  m1, m2 ~ Power-law + Peak model (GWTC-3)
      m1 ‚àà [5, 100], m2 ‚àà [5, 100]
      
BNS:  m1, m2 ~ Uniform [1, 3] M‚òâ
      
NSBH: m1 ~ Power-law [5, 50] M‚òâ (BH)
      m2 ~ Gaussian(1.4, 0.1) M‚òâ (NS)

# Distance distribution
d_L ~ log-uniform [50, 3000] Mpc
Includes cosmological corrections: d_L(z) with Planck 2018

# Sky position (isotropic)
RA ~ U(0, 2œÄ)
Dec ~ arcsin(U(-1, 1))  # Uniform on sphere

# Spin magnitudes
BBH:  a1, a2 ~ Beta(Œ±=2, Œ≤=4)  # Prefer lower spins
BNS:  a1, a2 ~ U(0, 0.05)      # Slow rotation
NSBH: a_BH ~ Beta(2, 4), a_NS ~ U(0, 0.05)

# Spin orientations
Aligned: Œ∏_tilt ~ N(0, 0.1) for œá_eff > 0
Precessing: Œ∏_tilt ~ U(0, œÄ) for precession
Isotropic: Œ∏_tilt ~ sin(Œ∏) (default)

# Orbital eccentricity (if eccentric edge case)
e_merger ~ U(0.3, 0.8)
```

### 2. Detector Network

**Active Detectors:** H1, L1, V1

**Noise Generation:**
```python
# PSD-based colored noise
n(t) = IFFT[‚àöS_n(f) ¬∑ ‚Ñú(Gaussian(0,1) + i¬∑Gaussian(0,1))]

# Where S_n(f) = Advanced LIGO/Virgo Design Sensitivity
```

**PSDs:**
- **H1/L1:** aLIGO Design Sensitivity (O3 era)
- **V1:** Advanced Virgo Design Sensitivity
- **Frequency Range:**  Hz[12]

**Glitch Injection (30% of samples):**
```python
Glitch types:
- Blip: Short duration (10-100 ms), SNR 10-30
- Whistle: Frequency chirp, 0.5-2 s, SNR 15-40
- Koi Fish: Arch shape in spectrogram, 0.1-0.5 s
- Wandering Line: Narrow spectral line drift

Injection: Add glitch to noise before signal injection
```

**Signal Projection:**
```python
# Detector response
h_det(t) = F+(Œ∏, œÜ, œà) ¬∑ h+(t) + Fx(Œ∏, œÜ, œà) ¬∑ hx(t)

# Antenna patterns F+, Fx for each detector
# Œ∏ (declination), œÜ (right ascension), œà (polarization)

# Final strain
s(t) = n(t) + Œ£·µ¢ h_det,i(t)  # Sum over overlapping signals
```

### 3. SNR Targeting

**Methodology:** Iterative scaling to achieve target network SNR

```python
# Optimal SNR calculation
œÅ_optimal = ‚àö(4 ‚à´ |hÃÉ(f)|¬≤ / S_n(f) df)

# Scale to target
scale_factor = œÅ_target / œÅ_optimal
h_scaled(t) = scale_factor ¬∑ h(t)

# Network SNR (quadrature sum)
œÅ_network = ‚àö(œÅ_H1¬≤ + œÅ_L1¬≤ + œÅ_V1¬≤)

# For overlapping signals
œÅ_total = ‚àö(Œ£·µ¢ œÅ·µ¢¬≤) for i signals
```

**SNR Assignment:**
- Drawn from 5-regime distribution (weak/low/medium/high/loud)
- Regime probabilities: 15%, 35%, 30%, 15%, 5%
- Within regime: uniform sampling

### 4. Overlapping Signal Generation

**Temporal Overlap Strategy:**

```python
# Number of signals
n_signals ~ Discrete({2: 0.70, 3: 0.25, 4: 0.04, 5: 0.01})

# Merger time separation
Œît_merger ~ U(0.1, 4.0) seconds

# Temporal overlap categories:
- Near-simultaneous: Œît < 0.2s (extreme case)
- High overlap:      0.2s ‚â§ Œît < 0.5s
- Moderate overlap:  0.5s ‚â§ Œît < 1.0s
- Low overlap:       1.0s ‚â§ Œît < 2.0s
- Partial overlap:   2.0s ‚â§ Œît < 4.0s (edge case)

# Reference time: center of 4s window
# Signals placed symmetrically around center
```

**SNR Distribution in Overlaps:**
```python
# Primary signal: highest SNR
œÅ_primary ~ SNR_DISTRIBUTION

# Secondary signals: relative to primary
œÅ_secondary ~ U(0.5¬∑œÅ_primary, œÅ_primary)

# For subtle_ranking edge case:
|œÅ_i - œÅ_j| < 3 for all pairs
```

### 5. Preprocessing Pipeline

**Whitening:**
```python
# Frequency domain whitening
hÃÉ_white(f) = hÃÉ(f) / ‚àöS_n(f)

# Apply Tukey window (Œ±=0.2) to prevent edge effects
# Convert back to time domain
```

**Band-pass Filter:**
```python
# 4th order Butterworth
f_low = 20 Hz
f_high = 1024 Hz (Nyquist/2 for 2048 Hz sampling)
```

**Normalization:**
```python
# Per-detector normalization
h_norm = (h - mean(h)) / std(h)

# Clip to [-5, 5] sigma to handle outliers
```

**Edge Tapering:**
```python
# Tukey window (Œ±=0.2)
# Smooth first/last 10% of segment
```

***

## Dataset Composition

### Regular Single Events (10,000 samples, 20.0%)

Standard astrophysical sources without special characteristics:

```python
# Parameter sampling
- Mass: From astrophysical distributions
- Distance: Log-uniform [50, 3000] Mpc
- Spins: Beta distribution (prefer lower spins)
- Sky position: Isotropic on sphere
- Target SNR: 5-regime distribution

# No special constraints
# Represent bulk of real gravitational wave detections
```

**Purpose:** Training on standard detection scenarios, baseline performance

### Pre-merger Samples (7,500 samples, 15.0%)

Inspiral-only signals without merger/ringdown in observation window:

```python
# Generation constraints
time_to_merger > duration/2  # Merger outside window
f_lower = 20 Hz
duration = 4 s

# Allows study of:
- Pure inspiral evolution
- Chirp mass estimation from inspiral only
- Long-duration low-frequency signals (especially BNS)
```

**Scientific Motivation:** O5/O6 will see many long-duration inspirals with mergers outside observation windows. Essential for understanding inspiral-only parameter estimation.

### Regular Overlaps (25,000 samples, 50.0%)

Multiple signals with varying temporal separations:

```python
# Configuration
n_signals: 2-5 (mostly 2-3)
Œît: 0.1-4.0 seconds
Mixed event types (BBH, BNS, NSBH)
Mixed SNRs across 5 regimes

# Overlap statistics
2 signals: 70%
3 signals: 25%
4 signals: 4%
5 signals: 1%
```

**Purpose:** Core training data for overlapping signal decomposition, priority ranking, multi-signal parameter estimation

***

## Edge Cases (20 Types)

**Total:** 7,886 samples (15.8% of dataset)

Edge cases represent **challenging but realistic scenarios** encountered in real gravitational wave searches. Essential for model robustness.

### Physical Extremes (2,445 samples, 4.9%)

#### 1. High Mass Ratio (400 samples)
```python
# Configuration
q = m2/m1 < 0.1
M_total: 5-100 M‚òâ
Waveform effects: Longer inspiral, asymmetric merger

# Example
m1 = 35 M‚òâ, m2 = 3 M‚òâ ‚Üí q = 0.086
```
**Motivation:** GW190814 had q ‚âà 0.11. High-q systems probe formation channels.

#### 2. Extreme Spins (400 samples)
```python
# Configuration
|a1| > 0.95 or |a2| > 0.95
œá_eff: uniform [-0.99, 0.99]
Waveform: IMRPhenomPv2 or SEOBNRv4 (spin effects)

# Example
a1 = 0.98, tilt1 = 0.1 rad ‚Üí highly spinning, aligned
```
**Motivation:** Tests limits of spin-orbit coupling, frame-dragging effects

#### 3. Eccentric Mergers (300 samples)
```python
# Configuration
e_merger ‚àà [0.3, 0.8]
Approximant: EccentricTD or TaylorF2Ecc
Waveform effects: Harmonic overtones, burst-like inspiral

# Example
e = 0.5 ‚Üí highly eccentric, dynamical capture
```
**Motivation:** Globular cluster/AGN disk formation channels produce eccentric binaries

#### 4. Precessing Systems (400 samples)
```python
# Configuration
Œ∏_tilt ‚àà [30¬∞, 150¬∞] (significant misalignment)
œá_p > 0.5
Observable: Modulation in amplitude/phase

# Example
a1 = 0.7, Œ∏1 = 60¬∞ ‚Üí strong precession
```
**Motivation:** ~30% of BBH show precession signatures (GW151226)

#### 5. Short Duration High Mass (300 samples)
```python
# Configuration
M_total > 100 M‚òâ
f_ISCO = 220/M_total > 44 Hz
Duration in [20, 1024] Hz < 0.5 s

# Example
m1 = 80 M‚òâ, m2 = 70 M‚òâ ‚Üí M = 150 M‚òâ, ~0.2s in band
```
**Motivation:** IMBH candidates, population III remnants (GW190521: 150 M‚òâ)

#### 6. Low SNR Threshold (200 samples)
```python
# Configuration
Network SNR ‚àà [8.0, 10.0]
May be sub-threshold in individual detectors
Requires network coherence

# Example
œÅ_H1 = 6.2, œÅ_L1 = 5.8, œÅ_V1 = 4.1 ‚Üí œÅ_net = 9.2
```
**Motivation:** Catalog completeness, population studies at detection threshold

#### 7. Extreme Mass Ratio (145 samples)
```python
# Configuration
q < 0.05
M_total < 30 M‚òâ
Long inspiral (many GW cycles)

# Example
m1 = 25 M‚òâ, m2 = 1.2 M‚òâ ‚Üí q = 0.048
```
**Motivation:** Intermediate-mass-ratio inspirals (IMRIs), probe of strong-field gravity

#### 8. Cosmological Distance (52 samples)
```python
# Configuration
d_L > 2000 Mpc (z > 0.5)
Network SNR < 10 (weak but detectable)
Cosmological effects: redshifted masses

# Example
z = 0.6 ‚Üí d_L = 3500 Mpc, m_det = 1.6 √ó m_source
```
**Motivation:** Cosmological studies, Hubble constant measurement

### Observational Extremes (2,000 samples, 4.0%)

#### 1. Strong Glitches (600 samples)
```python
# Configuration
Glitch types: Blip, Whistle, Koi Fish
Glitch SNR: 10-50
Temporal overlap with signal

# Example
Signal at t=2.0s + Blip at t=1.95s
```
**Motivation:** LIGO detects ~1 glitch/minute. Robustness to noise transients critical.

#### 2. Detector Dropout (400 samples)
```python
# Configuration
Active detectors: 1 or 2 (out of 3)
Strain zeroed for inactive detector(s)
Reduced sky localization

# Example
Only H1 and L1 active (V1 offline)
```
**Motivation:** ~15% observing time has 1+ detector down. Real-time analysis must handle.

#### 3. PSD Drift (400 samples)
```python
# Configuration
Time-varying S_n(f): ¬±20-50% variation
Simulates non-stationary noise
Affects whitening accuracy

# Example
S_n(f, t=0s) ‚Üí 1.3 √ó S_n(f, t=4s)
```
**Motivation:** Lock losses, environmental disturbances cause PSD changes

#### 4. Sky Position Extremes (600 samples)
```python
# Configuration
|Dec| > 75¬∞ (near celestial poles)
Or F+, Fx < 0.1 (poor antenna response)
Reduced SNR, poor localization

# Example
Dec = +82¬∞ ‚Üí near north celestial pole
```
**Motivation:** Network geometry reduces sensitivity at certain sky locations

### Statistical Extremes (2,000 samples, 4.0%)

#### 1. Multimodal Posteriors (800 samples)
```python
# Configuration
Parameter degeneracies:
- Inclination-distance (face-on/face-off)
- Mass-spin (higher mass + low spin ‚âà lower mass + high spin)
- Sky position (multiple arrival time solutions)

# Challenge
Multiple posterior peaks, difficult MCMC convergence
```
**Motivation:** ~20% of real events show multi-modality

#### 2. Heavy-Tailed Regions (1,167 samples)
```python
# Configuration
Parameters in distribution tails:
- Distance > 1200 Mpc (far tail)
- Mass > 70 M‚òâ (high-mass tail)
- Extreme spins, tilts, eccentricity

# Challenge
Test model extrapolation beyond training distribution bulk
```
**Motivation:** Rare events at parameter space boundaries

#### 3. Uninformative Priors (33 samples)
```python
# Configuration
Weakly constrained parameters:
- Near-equal mass: q > 0.95
- Low spins: |a| < 0.1
- Face-on/off: |Œπ| < 0.1 or |Œπ-œÄ| < 0.1

# Challenge
Prior-dominated posteriors, wide uncertainties
```
**Motivation:** Some parameters intrinsically hard to measure

### Overlap Extremes (1,441 samples, 2.9%)

#### 1. Subtle Ranking (314 samples)
```python
# Configuration
Similar-SNR overlapping signals
|œÅ_i - œÅ_j| < 3 for all signal pairs
Difficult priority assignment

# Example
Signal 1: œÅ = 14.2, Signal 2: œÅ = 12.8 ‚Üí ŒîœÅ = 1.4
```
**Motivation:** Tests priority network robustness

#### 2. Heavy Overlaps (586 samples)
```python
# Configuration
3-5 concurrent signals
High temporal overlap (Œît < 1.0s)
Mixed event types and SNRs

# Example
3 BBH signals within 0.6s window
```
**Motivation:** Stress test decomposition capacity

#### 3. Partial Overlaps (600 samples)
```python
# Configuration
Signals overlap only in inspiral or merger
Œît ‚àà [2.0, 4.0] seconds
Sequential signal processing challenge

# Example
Signal 1 inspiral overlaps Signal 2 merger
```
**Motivation:** Real-time analysis edge cases

---

## Extreme Cases (10 Types)

**Total:** 1,001 samples (2.0% of dataset)

Extreme cases are **rare but scientifically critical** scenarios essential for publication-quality validation. These probe edge-of-parameter-space physics.

### 1. Near-Simultaneous Mergers (157 samples)
```python
# Configuration
Œît_merger < 200 ms between 2-3 signals
Overlapping merger transients
Requires sub-second time resolution

# Scientific Motivation
- Hierarchical merger scenarios
- Dynamical formation in dense environments
- Tests rapid signal subtraction

# Example
GW1: BBH merger at t = 2.000s
GW2: BBH merger at t = 2.150s
Œît = 150 ms
```

### 2. Extreme Mass Ratio Inspirals (145 samples)
```python
# Configuration
q < 0.05
M_primary ‚àà [10, 30] M‚òâ
M_secondary ‚àà [1, 3] M‚òâ
Long inspiral: 1000+ GW cycles in band

# Scientific Motivation
- IMBHs (intermediate-mass black holes)
- Strong-field gravity tests
- Waveform systematics at extreme q

# Example
m1 = 25 M‚òâ, m2 = 1.2 M‚òâ
q = 0.048, œá_eff = 0.15
f_low = 20 Hz ‚Üí 850 cycles in band
```

### 3. High-Spin Aligned/Anti-Aligned (104 samples)
```python
# Configuration
|œá_eff| > 0.9
|a1|, |a2| > 0.95
|Œ∏_tilt| < 5¬∞ (aligned) or |Œ∏_tilt - 180¬∞| < 5¬∞ (anti-aligned)

# Scientific Motivation
- Formation channel discrimination
- Field binary vs dynamical assembly
- Tests maximal Kerr spin physics

# Example
a1 = 0.98, Œ∏1 = 2¬∞ (nearly perfectly aligned)
a2 = 0.96, Œ∏2 = 3¬∞
œá_eff = 0.95
```

### 4. Precession-Dominated (85 samples)
```python
# Configuration
œá_p > 0.8 (strong precession parameter)
Observable precession cycles in 4s window
Requires precessing waveform models

# Scientific Motivation
- Spin-orbit coupling measurements
- Binary formation history
- Precessing waveform systematics

# Example
a1 = 0.8, Œ∏1 = 60¬∞ (significant misalignment)
a2 = 0.7, Œ∏2 = 70¬∞
œá_p = 0.85
Precession period ~ 2s (observable)
```

### 5. Eccentric Overlaps (97 samples)
```python
# Configuration
e_merger > 0.3 for ‚â•2 overlapping signals
Temporal overlap Œît < 1.0s
Rare combination of eccentricity + overlap

# Scientific Motivation
- Dynamical environments (globular clusters, AGN disks)
- Tests eccentric waveform models
- Overlap + eccentricity degeneracies

# Example
Signal 1: e = 0.45, BBH
Signal 2: e = 0.55, BBH
Œît = 0.7s
```

### 6. Weak-Strong Overlaps (92 samples)
```python
# Configuration
Large SNR contrast: œÅ_max > 40, œÅ_min < 10
Weak signal "hidden" by strong signal
SNR ratio > 4:1

# Scientific Motivation
- Catalog completeness
- Subtraction residuals
- Hierarchical signal search

# Example
Signal 1: œÅ = 42 (loud BBH)
Signal 2: œÅ = 9.5 (weak BNS, near threshold)
```

### 7. Noise-Confused Overlaps (92 samples)
```python
# Configuration
Overlapping signals + strong glitches
Combined glitch+signal SNR > 50
Distinguishing signals from artifacts

# Scientific Motivation
- Real-world data challenges
- Data quality robustness
- Veto strategy development

# Example
2 BBH signals (œÅ = 18, 22) + Blip glitch (œÅ = 25)
Total "SNR": ‚àö(18¬≤ + 22¬≤ + 25¬≤) = 38
```

### 8. Long-Duration BNS Overlaps (52 samples)
```python
# Configuration
2-3 BNS signals
f_lower = 20 Hz
Combined duration in band > 60s

# Scientific Motivation
- O5/O6 dense observation periods
- BNS-specific challenges (tides, long inspiral)
- Multi-BNS science (rate estimates)

# Example
BNS 1: 35s in band, merger at t = 2.0s
BNS 2: 40s in band, merger at t = 3.5s
Total: 75s combined
```

### 9. Detector Dropouts (125 samples)
```python
# Configuration
Signal spans detector downtime transition
Starts with 3 detectors ‚Üí ends with 2 detectors
Or 2 ‚Üí 1 transition

# Scientific Motivation
- Real-time analysis robustness
- Duty cycle effects
- Network consistency checks

# Example
t = 0-2s: H1, L1, V1 active
t = 2-4s: H1, L1 only (V1 dropout at t=2s)
Signal merger at t = 2.5s
```

### 10. Cosmological Distance (52 samples)
```python
# Configuration
z > 0.5 (d_L > 2000 Mpc)
Network SNR ‚àà [8, 10] (threshold)
Cosmological corrections significant

# Scientific Motivation
- Cosmological studies (H‚ÇÄ, dark energy)
- Population models at high redshift
- Selection effects

# Example
z = 0.6
d_L = 3500 Mpc
m_source = (25, 20) M‚òâ ‚Üí m_detector = (40, 32) M‚òâ
œÅ_net = 9.2
```

***

## SNR Distribution

### Design Philosophy

SNR distribution follows **GWTC-3 catalog statistics** to ensure models train on realistic detection scenarios. The 5-regime binning matches LIGO/Virgo search pipelines.

### 5-Regime Distribution

#### Weak SNR (15.0% - Threshold Events)
```python
Range: œÅ ‚àà [8, 10)
Count: 13,616 signals
Purpose: Detection threshold, completeness studies
Characteristics:
- Just above detection threshold (œÅ_threshold ‚âà 8)
- May be sub-threshold in 1-2 detectors
- Requires network coherence
- High false alarm rate region

Example: Marginal detections requiring careful analysis
GWTC Analog: ~30% of O3 catalog
```

#### Low SNR (39.6% - Catalog Dominant)
```python
Range: œÅ ‚àà [10, 15)
Count: 36,062 signals (largest category)
Purpose: Most common detection regime in real data
Characteristics:
- Robust detections but moderate uncertainties
- Typical BBH merger at ~1 Gpc
- Sky localization: 10-100 deg¬≤

Example: GW190521 (network œÅ ‚âà 15)
GWTC Analog: ~50% of O3 catalog
```

#### Medium SNR (33.3% - Standard Detections)
```python
Range: œÅ ‚àà [15, 25)
Count: 30,340 signals
Purpose: Well-characterized events, good for parameter estimation
Characteristics:
- Clear detections in all detectors
- Typical BNS at 100-200 Mpc
- Sky localization: 1-10 deg¬≤
- Mass measurement: ~5-10% uncertainty

Example: GW190814 (network œÅ ‚âà 25)
GWTC Analog: ~15% of O3 catalog
```

#### High SNR (9.5% - Golden Events)
```python
Range: œÅ ‚àà [25, 40)
Count: 8,633 signals
Purpose: High-precision parameter estimation, waveform tests
Characteristics:
- Excellent in all detectors
- BNS at 50-100 Mpc, BBH at 500 Mpc
- Sky localization: < 1 deg¬≤
- Mass measurement: ~1-5% uncertainty
- Spin constraints possible

Example: GW170817 (network œÅ ‚âà 32)
GWTC Analog: ~3-4% of O3 catalog
```

#### Loud SNR (2.6% - Exceptional Detections)
```python
Range: œÅ ‚àà [40, 50+)
Count: 2,339 signals
Purpose: Nearby/massive sources, benchmark events, waveform systematics
Characteristics:
- Exceptional detections
- BBH at 200-400 Mpc, BNS at 10-40 Mpc
- Sub-arcsecond localization possible
- Sub-percent mass uncertainties
- Spin, tidal deformability measurable

Example: GW150914 (H1 œÅ ‚âà 24, loudest in O1)
GWTC Analog: ~1-2% of O3 catalog (GW150914, GW170817, etc.)
```

### Network SNR Calculation

```python
# Individual detector SNR
œÅ_det = ‚àö(4 ‚à´_{f_low}^{f_high} |hÃÉ(f)|¬≤ / S_n(f) df)

# Integration bounds
f_low = 20 Hz (low-frequency cutoff)
f_high = 1024 Hz (high-frequency cutoff, Nyquist/2)

# Network SNR (quadrature sum assuming uncorrelated noise)
œÅ_network = ‚àö(œÅ_H1¬≤ + œÅ_L1¬≤ + œÅ_V1¬≤)

# For overlapping signals (incoherent sum)
œÅ_total = ‚àö(Œ£·µ¢ œÅ·µ¢¬≤) for i signals

# Typical detector contributions (roughly equal sensitivity)
H1: ~40% of network SNR¬≤
L1: ~40% of network SNR¬≤
V1: ~20% of network SNR¬≤ (slightly less sensitive)
```

### SNR-Distance Relationship

```python
# Approximate scaling for BBH
œÅ ‚àù M_chirp^(5/6) / d_L

# Where M_chirp = (m1 * m2)^(3/5) / (m1 + m2)^(1/5)

# Example scalings (30 M‚òâ chirp mass)
d_L = 400 Mpc  ‚Üí œÅ ‚âà 40 (loud)
d_L = 800 Mpc  ‚Üí œÅ ‚âà 20 (high)
d_L = 1200 Mpc ‚Üí œÅ ‚âà 13 (medium)
d_L = 2000 Mpc ‚Üí œÅ ‚âà 8  (weak)
```

***

## Module Structure

```
ahsd/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py                    # Global configuration
‚îÇ   ‚îú‚îÄ‚îÄ dataset_generator.py         # Main generator class
‚îÇ   ‚îú‚îÄ‚îÄ parameter_sampler.py         # Astrophysical parameter sampling
‚îÇ   ‚îú‚îÄ‚îÄ waveform_generator.py        # Waveform generation (PyCBC interface)
‚îÇ   ‚îú‚îÄ‚îÄ signal_injector.py           # SNR-controlled injection
‚îÇ   ‚îú‚îÄ‚îÄ noise_generator.py           # Colored noise + glitches
‚îÇ   ‚îú‚îÄ‚îÄ psd_manager.py               # PSD loading/management
‚îÇ   ‚îú‚îÄ‚îÄ preprocessor.py              # Whitening, filtering, normalization
‚îÇ   ‚îú‚îÄ‚îÄ io_utils.py                  # Data I/O (HDF5, pickle, JSON)
‚îÇ   ‚îú‚îÄ‚îÄ validation.py                # Data quality checks
‚îÇ   ‚îú‚îÄ‚îÄ gwtc_loader.py               # Real event loading
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ scripts/
‚îÇ       ‚îú‚îÄ‚îÄ generate_dataset.py      # CLI generation script
‚îÇ       ‚îú‚îÄ‚îÄ validate_dataset.py      # CLI validation script
‚îÇ       ‚îî‚îÄ‚îÄ analyze_dataset.py       # Statistical analysis
‚îÇ
‚îî‚îÄ‚îÄ tests/
    ‚îú‚îÄ‚îÄ test_generator.py
    ‚îú‚îÄ‚îÄ test_sampler.py
    ‚îî‚îÄ‚îÄ test_injection.py
```

***

## Usage Examples

### Example 1: Custom Parameter Sampling

```python
from ahsd.data import ParameterSampler

sampler = ParameterSampler()

# Sample BBH parameters
bbh_params = sampler.sample_bbh_parameters(
    snr_regime='high',  # SNR 20-30
    is_edge_case=False
)

print(f"Mass 1: {bbh_params['mass_1']:.2f} M‚òâ")
print(f"Mass 2: {bbh_params['mass_2']:.2f} M‚òâ")
print(f"Distance: {bbh_params['luminosity_distance']:.0f} Mpc")
print(f"Redshift: {bbh_params['redshift']:.3f}")
print(f"Target SNR: {bbh_params['target_snr']:.1f}")
print(f"œá_eff: {bbh_params['chi_eff']:.2f}")
```

### Example 2: Generate Overlapping Scenario

```python
from ahsd.data import SignalInjector, NoiseGenerator, PSDManager

# Initialize components
psd_manager = PSDManager()
psds = psd_manager.load_detector_psds(['H1', 'L1', 'V1'])

noise_gen = NoiseGenerator()
injector = SignalInjector()

# Create overlapping scenario
scenario_params = injector.create_overlapping_scenario(
    n_signals=3,
    snr_range=(10, 25),
    overlap_window=0.5  # seconds
)

# Generate noise for H1
noise_h1 = noise_gen.generate_colored_noise(psds['H1'])

# Inject overlapping signals
injected_h1, metadata = injector.inject_overlapping_signals(
    noise_h1, scenario_params, 'H1', psds['H1']
)

print(f"Injected {len(scenario_params)} overlapping signals")
print(f"Time offsets: {[p['time_offset'] for p in scenario_params]}")
print(f"Individual SNRs: {[m['achieved_snr'] for m in metadata]}")
print(f"Network SNR: {metadata[0]['network_snr']:.1f}")
```

### Example 3: Load Real GWTC Events

```python
from ahsd.data import GWTCLoader

loader = GWTCLoader()

# Get all GWTC-4 events
events = loader.get_gwtc_events(catalog='GWTC-4')

print(f"Found {len(events)} events")
print(events[['event_name', 'mass_1_source', 'mass_2_source', 'network_snr']].head())

# Create synthetic overlaps from real events
overlaps = loader.create_synthetic_overlaps(
    events,
    n_overlaps=100,
    overlap_window=0.5
)

print(f"Created {len(overlaps)} synthetic overlapping scenarios")
```

### Example 4: Custom Preprocessing Pipeline

```python
from ahsd.data import DataPreprocessor
import numpy as np

preprocessor = DataPreprocessor(
    sample_rate=4096,
    duration=4.0,
    f_low=20.0,
    f_high=2048.0
)

# Load raw strain (example)
raw_strain = np.random.randn(16384)  # 4096 Hz * 4s

# Preprocess
processed = preprocessor.preprocess(
    raw_strain,
    psd_dict=psds['H1'],
    whiten=True,
    bandpass=True,
    remove_edges=True
)

# Validate
report = preprocessor.validate_data(processed)
print(f"Validation passed: {report['passed']}")
print(f"RMS: {report['metrics']['rms']:.2e}")
print(f"Max value: {report['metrics']['max_value']:.2f}")
print(f"NaN count: {report['metrics']['nan_count']}")
```

### Example 5: PyTorch Dataset Integration

```python
import torch
from torch.utils.data import Dataset, DataLoader
import pickle

class AHSDDataset(Dataset):
    def __init__(self, split_dir, transform=None):
        # Load all chunks
        self.samples = []
        chunk_files = sorted(split_dir.glob('chunk_*.pkl'))
        
        for chunk_file in chunk_files:
            with open(chunk_file, 'rb') as f:
                self.samples.extend(pickle.load(f))
        
        self.transform = transform
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        sample = self.samples[idx]
        
        # Stack detector strains: shape (3, 8192)
        strain = np.stack([
            sample['detector_data']['H1']['strain'],
            sample['detector_data']['L1']['strain'],
            sample['detector_data']['V1']['strain']
        ], axis=0)
        
        # Extract parameters
        params = sample['parameters']
        if isinstance(params, list):
            # Overlapping: concatenate all signal parameters
            params_list = []
            for p in params:
                params_list.extend([
                    p['mass_1'], p['mass_2'], p['luminosity_distance'],
                    p['ra'], p['dec'], p['target_snr']
                ])
            params_tensor = torch.tensor(params_list, dtype=torch.float32)
        else:
            # Single signal
            params_tensor = torch.tensor([
                params['mass_1'], params['mass_2'], params['luminosity_distance'],
                params['ra'], params['dec'], params['target_snr']
            ], dtype=torch.float32)
        
        strain_tensor = torch.tensor(strain, dtype=torch.float32)
        n_signals = sample['n_signals']
        
        if self.transform:
            strain_tensor = self.transform(strain_tensor)
        
        return strain_tensor, params_tensor, n_signals

# Create DataLoader
train_dataset = AHSDDataset(Path('data/dataset/train'))
train_loader = DataLoader(
    train_dataset,
    batch_size=32,
    shuffle=True,
    num_workers=4,
    pin_memory=True
)

# Training loop
for epoch in range(num_epochs):
    for strain, params, n_signals in train_loader:
        # Your training code here
        pass
```

***

## Configuration

### Default Parameters (`ahsd/data/config.py`)

```python
# Acquisition
SAMPLE_RATE = 4096  # Hz
DURATION = 4.0  # seconds
N_SAMPLES = 16384  # SAMPLE_RATE * DURATION

# Detectors
DETECTORS = ['H1', 'L1', 'V1']

# SNR Ranges (5 regimes)
SNR_RANGES = {
    'weak': (8, 10),
    'low': (10, 14),
    'medium': (14, 20),
    'high': (20, 30),
    'loud': (30, 50)
}

# SNR Distribution (GWTC-3 based)
SNR_DISTRIBUTION = {
    'weak': 0.15,
    'low': 0.35,
    'medium': 0.30,
    'high': 0.15,
    'loud': 0.05
}

# Event Types
EVENT_TYPE_DISTRIBUTION = {
    'BBH': 0.50,
    'BNS': 0.30,
    'NSBH': 0.15,
    'noise': 0.05
}

# Mass Ranges (M‚òâ)
MASS_RANGES = {
    'BBH': {'m1': (5.0, 100.0), 'm2': (5.0, 100.0)},
    'BNS': {'m1': (1.0, 2.5), 'm2': (1.0, 2.5)},
    'NSBH': {'m1': (3.0, 100.0), 'm2': (1.0, 2.5)}
}

# Distance Ranges (Mpc)
DISTANCE_RANGES = {
    'BBH': (100.0, 2000.0),
    'BNS': (10.0, 300.0),
    'NSBH': (20.0, 800.0)
}

# Cosmology (Planck 2018)
COSMO_H0 = 67.4  # km/s/Mpc
COSMO_OMEGA_M = 0.315
COSMO_OMEGA_LAMBDA = 0.685

# Edge Case Configuration
EDGE_CASE_FRACTION = 0.15
OVERLAP_FRACTION = 0.50

# Preprocessing
F_LOW = 20.0  # Hz
F_HIGH = 1024.0  # Hz (Nyquist/2)
WHITEN = True
BANDPASS = True

# Glitches
GLITCH_PROBABILITY = 0.30
GLITCH_TYPES = ['blip', 'whistle', 'koi_fish', 'wandering_line']
```

### Custom Configuration YAML

```yaml
# my_config.yaml
sample_rate: 4096
duration: 4.0
detectors: ['H1', 'L1', 'V1']

# Dataset composition
overlap_fraction: 0.50
edge_case_fraction: 0.15
premerger_fraction: 0.15

# Event distribution
event_distribution:
  BBH: 0.50
  BNS: 0.30
  NSBH: 0.15
  noise: 0.05

# SNR distribution
snr_distribution:
  weak: 0.15
  low: 0.35
  medium: 0.30
  high: 0.15
  loud: 0.05

# Edge cases configuration
edge_cases:
  physical_extremes:
    enabled: true
    fraction: 0.04
    types:
      high_mass_ratio: {fraction: 0.20}
      extreme_spins: {fraction: 0.20}
      eccentric_mergers: {fraction: 0.15}
      precessing_systems: {fraction: 0.20}
      short_duration_high_mass: {fraction: 0.15}
      low_snr_threshold: {fraction: 0.10}
  
  observational_extremes:
    enabled: true
    fraction: 0.04
    types:
      strong_glitches: {fraction: 0.30}
      detector_dropout: {fraction: 0.20}
      psd_drift: {fraction: 0.20}
      sky_position_extremes: {fraction: 0.30}
  
  statistical_extremes:
    enabled: true
    fraction: 0.04
    types:
      multimodal_posteriors: {fraction: 0.40}
      heavy_tailed_regions: {fraction: 0.30}
      uninformative_priors: {fraction: 0.30}
  
  overlapping_extremes:
    enabled: true
    fraction: 0.03
    types:
      subtle_ranking: {fraction: 0.30}
      heavy_overlaps: {fraction: 0.30}
      partial_overlaps: {fraction: 0.40}

# Extreme cases configuration
extreme_cases:
  enabled: true
  fraction: 0.02
  types:
    near_simultaneous_mergers: {fraction: 0.15}
    extreme_mass_ratio: {fraction: 0.15}
    high_spin_aligned: {fraction: 0.10}
    precession_dominated: {fraction: 0.08}
    eccentric_overlaps: {fraction: 0.10}
    weak_strong_overlaps: {fraction: 0.09}
    noise_confused_overlaps: {fraction: 0.09}
    long_duration_bns_overlaps: {fraction: 0.05}
    detector_dropouts: {fraction: 0.12}
    cosmological_distance: {fraction: 0.05}

# Preprocessing
preprocessing:
  whiten: true
  bandpass: true
  f_low: 20.0
  f_high: 1024.0
  remove_edges: true

# Glitches
glitches:
  enabled: true
  probability: 0.30
  types: ['blip', 'whistle', 'koi_fish']
```

**Load and use:**

```python
import yaml
from ahsd.data import GWDatasetGenerator

with open('my_config.yaml') as f:
    config = yaml.safe_load(f)

generator = GWDatasetGenerator(
    output_dir="data/custom",
    sample_rate=config['sample_rate'],
    duration=config['duration'],
    detectors=config['detectors']
)

# Override config
import ahsd.data.config as default_config
default_config.EVENT_TYPE_DISTRIBUTION = config['event_distribution']

summary = generator.generate_dataset(
    n_samples=10000,
    overlap_fraction=config['overlap_fraction'],
    edge_case_fraction=config['edge_case_fraction']
)
```

***

## Dataset Format

### Sample Dictionary Structure

```python
sample = {
    # ========== IDENTIFICATION ==========
    'id': str,  # 'overlap_012345', 'BBH_012345', 'sample_012345'
    'type': str,  # 'BBH' | 'BNS' | 'NSBH' | 'noise' | 'overlap'
    
    # ========== FLAGS ==========
    'is_overlap': bool,
    'is_edge_case': bool,
    'is_extreme_case': bool,
    
    # ========== CLASSIFICATION ==========
    'edge_case_type': str,  # See Edge Cases section
    'extreme_case_type': str,  # See Extreme Cases section
    
    # ========== SIGNAL COUNT ==========
    'n_signals': int,  # 1 for single, 2-5 for overlaps
    
    # ========== PARAMETERS ==========
    # For single signal:
    'parameters': {
        # Intrinsic parameters
        'mass_1': float,  # Primary mass [5, 100] M‚òâ
        'mass_2': float,  # Secondary mass [5, 100] M‚òâ
        'luminosity_distance': float,  # [50, 3000] Mpc
        'redshift': float,  # Cosmological redshift
        
        # Extrinsic parameters
        'ra': float,  # Right ascension [0, 2œÄ] rad
        'dec': float,  # Declination [-œÄ/2, œÄ/2] rad
        'geocent_time': float,  # GPS time or relative time (s)
        'theta_jn': float,  # Inclination [0, œÄ] rad
        'psi': float,  # Polarization angle [0, œÄ] rad
        'phase': float,  # Coalescence phase [0, 2œÄ] rad
        
        # Spin parameters
        'a1': float,  # Primary spin magnitude [0, 0.99]
        'a2': float,  # Secondary spin magnitude [0, 0.99]
        'tilt1': float,  # Primary spin tilt [0, œÄ] rad
        'tilt2': float,  # Secondary spin tilt [0, œÄ] rad
        'phi_12': float,  # Spin azimuthal separation [0, 2œÄ] rad
        'phi_jl': float,  # Spin-orbit azimuthal [0, 2œÄ] rad
        
        # Derived quantities
        'target_snr': float,  # Network SNR
        'chi_eff': float,  # Effective inspiral spin [-1, 1]
        'chi_p': float,  # Effective precession spin [0, 1]
        'chirp_mass': float,  # Chirp mass M‚òâ
        'total_mass': float,  # Total mass M‚òâ
        'mass_ratio': float,  # q = m2/m1 ‚àà [0, 1]
        'symmetric_mass_ratio': float,  # Œ∑ ‚àà [0, 0.25]
        
        # Optional parameters
        'eccentricity': float,  # If eccentric (default 0)
        'f_lower': float,  # Starting frequency [20, 40] Hz
        'lambda1': float,  # Tidal deformability (BNS/NSBH only)
        'lambda2': float,
    },
    
    # For overlapping signals:
    'parameters': [
        {...},  # Signal 1 parameters
        {...},  # Signal 2 parameters
        ...
    ],
    
    # ========== DETECTOR DATA ==========
    'detector_data': {
        'H1': {
            'strain': np.ndarray,  # Shape: (8192,), dtype: float32
            'psd': np.ndarray,  # Power spectral density (4097,)
            'frequencies': np.ndarray,  # Frequency array (4097,)
            'snr': float,  # Individual detector SNR
            'optimal_snr': float,  # Optimal SNR (before noise)
        },
        'L1': {...},
        'V1': {...},
    },
    
    # ========== METADATA ==========
    'metadata': {
        'sample_id': int,
        'event_type': str,  # 'BBH', 'BNS', 'NSBH', 'overlap'
        'detector_network': list,  # ['H1', 'L1', 'V1']
        'n_signals': int,
        'signal_parameters': list,  # Full parameter details
        
        # Edge case info
        'is_edge_case': bool,
        'edge_case_type': str,
        'edge_case_category': str,  # 'physical', 'observational', 'statistical', 'overlap'
        
        # Overlap info
        'overlap_type': str,  # If overlap
        'temporal_separations': list,  # Œît between signals
        
        # Generation info
        'generation_method': str,
        'approximant': str,  # Waveform approximant
        'sample_rate': float,  # 4096 Hz
        'duration': float,  # 4 seconds
        'timestamp': str,  # Generation timestamp
        
        # Noise info
        'has_glitch': bool,
        'glitch_type': str,
        'glitch_time': float,
        'glitch_snr': float,
        
        # Quality flags
        'validated': bool,
        'preprocessing_applied': bool,
    },
    
    # ========== EXTREME CASE METADATA (if applicable) ==========
    'extreme_metadata': {
        'extreme_case_type': str,
        'delta_t_max_ms': float,  # Max time separation (overlaps)
        'n_signals': int,
        'event_types': list,  # ['BBH', 'BBH', 'BNS']
        'temporal_overlap': str,  # 'near_simultaneous', 'high', 'moderate'
        'special_characteristics': dict,
        'mass_ratio_min': float,
        'spin_magnitudes': list,
        'eccentricities': list,
    },
}
```

### Array Specifications

```python
# Strain data (whitened, preprocessed)
strain: np.ndarray
  Shape: (8192,)
  Dtype: np.float32
  Units: Dimensionless (whitened)
  Range: Typically [-5, 5] after normalization

# Time array
time: np.ndarray
  Shape: (8192,)
  Dtype: np.float64
  Range: [0, 4] seconds
  Sample spacing: 1/4096 = 0.000244 s

# Frequency array (for PSD)
frequencies: np.ndarray
  Shape: (4097,)
  Dtype: np.float64
  Range: [0, 2048] Hz
  Spacing: 0.5 Hz

# PSD
psd: np.ndarray
  Shape: (4097,)
  Dtype: np.float64
  Units: Hz^(-1)
  Typical range: 10^(-48) to 10^(-44) Hz^(-1)
```

***

## File Structure

```
data/dataset/
‚îÇ
‚îú‚îÄ‚îÄ README.md                          # Dataset documentation
‚îú‚îÄ‚îÄ generation_config.yaml             # Generation parameters
‚îú‚îÄ‚îÄ generation_summary.json            # Statistics (samples, time, rate)
‚îú‚îÄ‚îÄ split_indices.json                 # Train/val/test sample indices
‚îú‚îÄ‚îÄ dataset_analysis.json              # Validation results
‚îú‚îÄ‚îÄ training_config.json               # Model training config (if applicable)
‚îÇ
‚îú‚îÄ‚îÄ detector_psds/                     # Power spectral densities
‚îÇ   ‚îú‚îÄ‚îÄ H1_psd.npz                     # LIGO Hanford
‚îÇ   ‚îú‚îÄ‚îÄ L1_psd.npz                     # LIGO Livingston
‚îÇ   ‚îî‚îÄ‚îÄ V1_psd.npz                     # Virgo
‚îÇ
‚îú‚îÄ‚îÄ train/                             # Training split (39,997 samples)
‚îÇ   ‚îú‚îÄ‚îÄ train_metadata.pkl             # Split metadata
‚îÇ   ‚îú‚îÄ‚îÄ chunk_0000.pkl                 # ~100 samples per chunk
‚îÇ   ‚îú‚îÄ‚îÄ chunk_0001.pkl
‚îÇ   ‚îú‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ chunk_0400.pkl                 # 401 chunks total
‚îÇ
‚îú‚îÄ‚îÄ validation/                        # Validation split (4,999 samples)
‚îÇ   ‚îú‚îÄ‚îÄ validation_metadata.pkl
‚îÇ   ‚îú‚îÄ‚îÄ chunk_0000.pkl
‚îÇ   ‚îú‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ chunk_0050.pkl                 # 51 chunks total
‚îÇ
‚îú‚îÄ‚îÄ test/                              # Test split (5,004 samples)
‚îÇ   ‚îú‚îÄ‚îÄ test_metadata.pkl
‚îÇ   ‚îú‚îÄ‚îÄ chunk_0000.pkl
‚îÇ   ‚îú‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ chunk_0051.pkl                 # 52 chunks total
‚îÇ
‚îî‚îÄ‚îÄ logs/
    ‚îú‚îÄ‚îÄ generation_20251023_060214.log # Generation log
    ‚îú‚îÄ‚îÄ validation_20251023_120315.log # Validation log
    ‚îî‚îÄ‚îÄ analysis_20251023_133045.log   # Analysis log
```

### Chunk File Format

```python
# Each chunk_XXXX.pkl contains:
chunk_data = [
    sample_0,  # Dictionary (see Dataset Format)
    sample_1,
    ...
    sample_99,
]  # List of ~100 sample dictionaries
```

### Metadata Files

```python
# train_metadata.pkl
metadata = {
    'split': 'train',
    'total_samples': 39997,
    'n_chunks': 401,
    'chunk_size': 100,
    'event_type_distribution': {
        'BBH': 8820,
        'BNS': 5304,
        'NSBH': 3816,
        'noise': 465,
        'overlap': 21592
    },
    'edge_case_count': 6248,
    'extreme_case_count': 801,
    'generation_date': '2025-10-23',
    'generation_time_minutes': 453.1,
    'validation_passed': True
}
```
API Reference
Core Classes
GWDatasetGenerator
Main class for comprehensive dataset generation with edge and extreme cases.

python
class GWDatasetGenerator:
    """
    Production-ready GW dataset generator with edge/extreme case support.
    
    Attributes:
        output_dir: Output directory path
        sample_rate: Sampling frequency (Hz)
        duration: Segment duration (seconds)
        detectors: List of detector names ['H1', 'L1', 'V1']
    """
    
    def __init__(
        self,
        output_dir: str = "data/output",
        sample_rate: int = 4096,
        duration: float = 4.0,
        detectors: List[str] = ['H1', 'L1', 'V1']
    )
    
    def generate_dataset(
        self,
        n_samples: int = 1000,
        overlap_fraction: float = 0.5,
        edge_case_fraction: float = 0.15,
        extreme_case_fraction: float = 0.02,
        save_batch_size: int = 100,
        add_glitches: bool = True,
        preprocess: bool = True,
        random_seed: int = None
    ) -> Dict[str, Any]:
        """
        Generate complete dataset with train/val/test splits.
        
        Returns:
            summary: Dictionary with generation statistics
        """
ParameterSampler
Astrophysical parameter sampling with edge case support.
```
python
class ParameterSampler:
    """Sample astrophysically realistic parameters."""
    
    def sample_bbh_parameters(
        self,
        snr_regime: str,
        is_edge_case: bool = False,
        edge_case_type: str = None
    ) -> Dict[str, float]
    
    def sample_bns_parameters(
        self,
        snr_regime: str,
        is_edge_case: bool = False
    ) -> Dict[str, float]
    
    def sample_nsbh_parameters(
        self,
        snr_regime: str,
        is_edge_case: bool = False
    ) -> Dict[str, float]
SignalInjector
SNR-controlled signal injection with overlap support.

python
class SignalInjector:
    """Inject gravitational wave signals with precise SNR control."""
    
    def inject_signal(
        self,
        noise: np.ndarray,
        params: Dict[str, float],
        detector_name: str,
        psd_dict: Dict = None
    ) -> Tuple[np.ndarray, Dict]
    
    def inject_overlapping_signals(
        self,
        noise: np.ndarray,
        signal_params_list: List[Dict],
        detector_name: str,
        psd_dict: Dict = None
    ) -> Tuple[np.ndarray, List[Dict]]
    
    def create_overlapping_scenario(
        self,
        n_signals: int,
        snr_range: Tuple[float, float],
        overlap_window: float
    ) -> List[Dict]
NoiseGenerator
Realistic detector noise generation.

python
class NoiseGenerator:
    """Generate colored Gaussian noise and glitches."""
    
    def generate_colored_noise(
        self,
        psd: np.ndarray,
        duration: float = 4.0,
        sample_rate: int = 4096
    ) -> np.ndarray
    
    def add_glitch(
        self,
        strain: np.ndarray,
        glitch_type: str,
        glitch_time: float,
        glitch_snr: float
    ) -> np.ndarray
DataPreprocessor
Whitening, filtering, and normalization.

python
class DataPreprocessor:
    """Preprocess strain data for ML models."""
    
    def preprocess(
        self,
        strain: np.ndarray,
        psd_dict: Dict,
        whiten: bool = True,
        bandpass: bool = True,
        remove_edges: bool = True
    ) -> np.ndarray
    
    def validate_data(
        self,
        strain: np.ndarray
    ) -> Dict[str, Any]
Validation
Automated Validation Script
bash
# Full dataset validation
python -m ahsd.data.scripts.validate_dataset \
    --dataset-dir data/dataset \
    --config configs/data_config.yaml \
    --verbose

# Quick validation (first 1000 samples per split)
python -m ahsd.data.scripts.validate_dataset \
    --dataset-dir data/dataset \
    --quick \
    --max-samples 1000
Validation Checks
1. Distribution Validation
Event types: BBH/BNS/NSBH/noise match expected ratios

SNR regimes: 5-regime distribution (weak/low/medium/high/loud)

Overlap fraction: 50% target with adaptive tolerance

Tolerance: 5% for >1000 samples, 10% for smaller splits

2. Edge Case Validation
Total fraction: 15.8% target (¬±2% tolerance)

Category breakdown: Physical/Observational/Statistical/Overlap

Type presence: All 20 edge case types present

Minimum counts: ‚â•10 samples per type in training set

3. Extreme Case Validation
Total fraction: 2.0% target (¬±0.5% tolerance)

Type presence: All 10 extreme case types present

Minimum counts: ‚â•5 samples per type

Scientific validity: Parameters within physical bounds

4. Data Quality
Array integrity: No NaN/Inf values in strain data

Shape consistency: All strains (8192,), all PSDs (4097,)

Dtype correctness: strain=float32, time/freq=float64

Parameter bounds: All parameters within specified ranges

SNR accuracy: Achieved SNR within 10% of target

5. Metadata Consistency
Required fields: All samples have id, type, parameters, detector_data

Edge case labeling: is_edge_case flag matches edge_case_type presence

Detector network: All 3 detectors present (unless dropout edge case)

Timestamps: Valid generation timestamps

Expected Validation Output
text
==================================================================
AHSD DATASET VALIDATION REPORT
==================================================================
Dataset: data/dataset
Generated: 2025-10-23 06:02:52
Validation: 2025-10-23 13:15:30

[TRAIN SPLIT] ==========================================
‚úì Found 401 chunks, 39,997 samples
‚úì Event distribution: PASSED (max diff: 0.3%)
‚úì SNR distribution: PASSED (max diff: 4.6%)
‚úì Edge cases: 6,248 (15.6%) - PASSED
‚úì Extreme cases: 801 (2.0%) - PASSED
‚úì Data quality: PASSED (0 errors)

[VALIDATION SPLIT] =====================================
‚úì Found 51 chunks, 4,999 samples
‚úì Event distribution: PASSED
‚úì SNR distribution: PASSED
‚úì Edge cases: 810 (16.2%) - PASSED
‚úì Data quality: PASSED

[TEST SPLIT] ===========================================
‚úì Found 52 chunks, 5,004 samples
‚úì Event distribution: PASSED
‚úì SNR distribution: PASSED
‚úì Edge cases: 828 (16.5%) - PASSED
‚úì Data quality: PASSED

==================================================================
‚úÖ OVERALL VALIDATION: PASSED
==================================================================
Total samples: 50,000
Generation rate: 1.47 samples/s
Validation time: 234.5 s

Edge case coverage: 20/20 types ‚úì
Extreme case coverage: 10/10 types ‚úì
No critical issues detected.

Report saved: data/dataset/validation_report_20251023_131530.json
Manual Validation Checks
For publication, perform these additional manual checks:

python
from ahsd.data.io_utils import DatasetReader
import numpy as np

reader = DatasetReader()

# Load sample
sample = reader.load_pkl("data/dataset/train/chunk_0000.pkl")[0]

# Check 1: Waveform sanity
strain = sample['detector_data']['H1']['strain']
assert strain.shape == (8192,)
assert np.all(np.isfinite(strain))
assert np.abs(strain.mean()) < 0.1  # Should be ~0 after whitening
print(f"‚úì Strain: shape={strain.shape}, mean={strain.mean():.3e}, std={strain.std():.2f}")

# Check 2: SNR consistency
achieved_snr = sample['detector_data']['H1']['snr']
target_snr = sample['parameters']['target_snr']
network_snr = np.sqrt(sum(sample['detector_data'][d]['snr']**2 for d in ['H1','L1','V1']))
print(f"‚úì SNR: target={target_snr:.1f}, network={network_snr:.1f}, H1={achieved_snr:.1f}")

# Check 3: Parameter validity
params = sample['parameters']
assert 5 <= params['mass_1'] <= 100
assert 50 <= params['luminosity_distance'] <= 3000
print(f"‚úì Parameters: m1={params['mass_1']:.1f}, d={params['luminosity_distance']:.0f} Mpc")

# Check 4: Edge case labeling
if sample.get('is_edge_case'):
    assert sample.get('edge_case_type') is not None
    print(f"‚úì Edge case: {sample['edge_case_type']}")
Citation
If you use this dataset or generation module in your research, please cite:

text
@dataset{ahsd_gw_dataset_2025,
  author = {Thomas, Bibin},
  title = {AHSD Gravitational Wave Dataset: A Large-Scale Benchmark 
           for Overlapping Signal Detection and Parameter Estimation},
  year = {2025},
  month = {October},
  version = {1.0},
  publisher = {GitHub},
  url = {https://github.com/bibinthomas123/PosteriFlow},
  note = {50,000 samples with 90,990 gravitational wave signals, 
          including 7,886 edge cases and 1,001 extreme cases}
}

@software{posteriflow_2025,
  author = {Thomas, Bibin},
  title = {PosteriFlow: Neural Posterior Estimation for Overlapping 
           Gravitational Waves},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/bibinthomas123/PosteriFlow},
  version = {1.0.0}
}
Related Publications
This dataset was created for:

"Adaptive Hierarchical Signal Decomposition for Gravitational Wave Detection
in Overlapping Scenarios"
Bibin Thomas et al.
Physical Review D (in preparation), 2025

Acknowledgments
LIGO Scientific Collaboration for detector PSDs, design sensitivities, and GWTC catalogs

Virgo Collaboration for Virgo detector characterization

PyCBC Development Team for waveform generation infrastructure

LALSuite Team for gravitational wave simulation tools

GWTC-3 Collaboration for astrophysical distribution validation

Dependencies & Software
text
Core Dependencies:
  - pycbc >= 2.3.0
  - lalsuite >= 7.5
  - numpy >= 1.24
  - scipy >= 1.11
  - h5py >= 3.8

Optional:
  - gwpy >= 3.0 (real data access)
  - matplotlib >= 3.7 (visualization)
  - pandas >= 2.0 (GWTC loading)
  - torch >= 2.0 (ML integration)
Known Issues & Limitations
Current Limitations
Higher-order modes: Waveforms use dominant (‚Ñì,m) = (2,2) mode only

Impact: ~5-10% error in parameter estimation for high-mass, high-SNR systems

Mitigation: Use IMRPhenomHM for m1+m2 > 80 M‚òâ in future versions

Tidal deformability: BNS use point-particle approximation

Impact: Tidal effects not included in BNS waveforms

Mitigation: Use IMRPhenomD_NRTidalv2 for Œª1, Œª2 in v2.0

Precession systematics: Precessing waveforms limited to IMRPhenomPv2

Impact: May not capture all precession dynamics

Mitigation: Add SEOBNRv4P support

PSD stationarity: Assumes constant PSD over 4-second segments

Impact: Real detector PSD drifts on ~10-100s timescales

Mitigation: PSD drift edge case partially addresses this

Calibration uncertainties: Not included

Impact: Real data has ~5-10% amplitude uncertainty, ~1¬∞ phase uncertainty

Mitigation: Future version will add calibration error injection

Waveform systematics: Approximant-dependent errors not quantified

Impact: Unknown systematic bias from waveform models

Mitigation: Validate against numerical relativity for subset

Planned Updates (Version 2.0)
Targeted Release: Q1 2026

 Include higher-order modes (‚Ñì,m) = (2,1), (3,3), (4,4) for high-mass BBH

 Add tidal deformability for BNS/NSBH (Œª1, Œª2 sampling)

 Variable-length segments (1-16 seconds)

 Real LIGO/Virgo noise from O3/O4 observing runs

 Calibration uncertainty injection (magnitude + phase errors)

 4-detector network (add KAGRA)

 Eccentric waveforms for all mass ranges (currently limited)

 Sub-solar mass primordial black holes (0.5-5 M‚òâ)

 Intermediate-mass black holes (100-10,000 M‚òâ)

 Lensed signals (strong gravitational lensing scenarios)

Troubleshooting
Common Issues
Issue: "PyCBC approximant not found"

bash
# Solution: Install LALSuite
conda install -c conda-forge lalsuite
Issue: "Memory error during generation"

bash
# Solution: Reduce batch size
generator.generate_dataset(n_samples=50000, save_batch_size=50)  # Was 100
Issue: "Validation fails on SNR distribution"

python
# This is often due to random sampling variation in small datasets
# For n < 1000, use relaxed tolerance:
python validate_dataset.py --tolerance 0.15  # Default: 0.05
Issue: "Chunk file corrupted"

bash
# Regenerate specific chunk
python -m ahsd.data.scripts.regenerate_chunk \
    --dataset-dir data/dataset/train \
    --chunk-id 42
Performance Benchmarks
Generation Performance
Hardware	Samples/sec	50k Dataset Time	Memory Usage
AWS t3.2xlarge (8 vCPU, 32 GB)	1.47	9.4 hours	28 GB peak
AWS c5.4xlarge (16 vCPU, 32 GB)	2.85	4.9 hours	30 GB peak
Workstation (32 core, 64 GB)	4.12	3.4 hours	45 GB peak
Loading Performance
Operation	Time (train split)	Throughput
Load 1 chunk (100 samples)	0.15 s	667 samples/s
Load full split (40k)	58.3 s	686 samples/s
PyTorch DataLoader (batch=32)	0.048 s/batch	667 samples/s
License & Support
Dataset License
CC BY 4.0 (Creative Commons Attribution 4.0 International)

You are free to:

Share: Copy and redistribute in any medium or format

Adapt: Remix, transform, and build upon the material

Under the following terms:

Attribution: Must cite this dataset and related publications

Code License
MIT License

text
Copyright (c) 2025 Bibin Thomas

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
Contact & Support
Dataset Creator: Bibin Thomas
Email: bibinthomas951@gmail.com
GitHub: https://github.com/bibinthomas123/PosteriFlow
Issues: https://github.com/bibinthomas123/PosteriFlow/issues
Documentation: https://github.com/bibinthomas123/PosteriFlow/docs

For questions about:

Dataset usage: Open GitHub issue with tag dataset

Generation bugs: Open issue with tag bug + reproduction steps

Feature requests: Open issue with tag enhancement

Scientific collaboration: Email directly

Community
Discussions: https://github.com/bibinthomas123/PosteriFlow/discussions

Contributing: See CONTRIBUTING.md for guidelines

Code of Conduct: We follow the LIGO Scientific Collaboration Code of Conduct

Changelog
Version 1.0.0 (October 2025)
Initial Release

50,000 samples with 90,990 gravitational wave signals

3-detector network (H1, L1, V1)

20 edge case types (7,886 samples)

10 extreme case types (1,001 samples)

5-regime SNR distribution matching GWTC-3

Automated validation pipeline

Comprehensive documentation

Frequently Asked Questions
Q: Can I use this dataset for commercial applications?
A: Yes, under CC BY 4.0 license. Attribution required.

Q: How do I add my own edge case types?
A: See docs/EXTENDING.md for custom edge case implementation guide.

Q: Is the 50k dataset available for download?
A: Dataset will be released on Zenodo upon paper acceptance. Generation code available now.

Q: Can I generate datasets with different parameters?
A: Yes! The generation module is fully configurable. See Configuration section.

Q: How does this compare to other GW datasets?
A: This is the first large-scale dataset specifically designed for overlapping signals with comprehensive edge case coverage.

Q: What about binary neutron star tidal effects?
A: Currently uses point-particle approximation. Tidal deformability planned for v2.0.

Q: Can I contribute edge case definitions?
A: Yes! See CONTRIBUTING.md. We welcome scientifically motivated edge cases.

Last Updated: October 23, 2025
Version: 1.0.0
Status: Production Ready ‚úÖ

Generated with AHSD Dataset Generator v1.0
Validated: October 23, 2025 ‚úì
Publication Status: In Preparation

[1](https://www.nature.com/articles/s41598-021-98821-z)
[2](https://arxiv.org/html/2509.10505v5)
[3](https://dcc.ligo.org/public/0007/P070111/000/P070111-00.pdf)
[4](https://link.aps.org/doi/10.1103/PhysRevD.106.122001)
[5](https://pure.mpg.de/rest/items/item_150854/component/file_150852/content)
[6](http://arxiv.org/pdf/2405.17400.pdf)
[7](https://cds.cern.ch/record/2777883/files/document.pdf)
[8](https://research-portal.uu.nl/ws/files/241237807/PhysRevD.109.042005.pdf)
[9](https://www.arxiv.org/pdf/2508.05018.pdf)
[10](https://iphysresearch.github.io/Survey4GWML/)
[11](https://www.microsoft.com/en-us/research/project/datasheets-for-datasets/)
[12](https://sites.research.google/datacardsplaybook/)