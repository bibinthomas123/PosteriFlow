#!/usr/bin/env python3
"""
Best-in-class Neural Posterior Estimator with:
- RL-controlled adaptive complexity
- Advanced normalizing flows (RealNVP/MAF)
- Hierarchical bias correction
- Physics-informed priors
- Uncertainty quantification
- Multi-scale feature extraction
"""

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.distributions import MultivariateNormal, Normal
from typing import List, Dict, Any, Tuple, Optional, Union
import logging
import warnings
import time
from collections import deque
import random

warnings.filterwarnings("ignore", category=UserWarning)



class NeuralPosteriorEstimator(nn.Module):
    """ Neural Posterior Estimator using normalizing flows."""
    
    def __init__(self, param_names: List[str], config: Dict[str, Any]):
        super().__init__()
        self.param_names = param_names
        self.param_dim = len(param_names)
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # Configuration
        self.flow_layers = config.get('flow_layers', 6)
        self.hidden_features = config.get('hidden_features', 128)
        self.context_features = config.get('context_features', 256)
        
        # Parameter bounds for normalization
        self.param_bounds = self._get_parameter_bounds()
        
        # Context encoder - processes strain data into fixed-size features
        self.context_encoder = self._build_context_encoder()
        
        # Normalizing flow layers
        self.flow_layers_list = nn.ModuleList()
        for i in range(self.flow_layers):
            # Alternating masks
            mask = torch.zeros(self.param_dim)
            if i % 2 == 0:
                mask[::2] = 1
            else:
                mask[1::2] = 1
            
            layer = NVPLayer(self.param_dim, self.hidden_features, mask)
            self.flow_layers_list.append(layer)
        
        # Base distribution
        self.register_buffer('base_mean', torch.zeros(self.param_dim))
        self.register_buffer('base_cov', torch.eye(self.param_dim))
        
        self.logger.info(f"âœ…  Neural PE initialized: {self.param_dim} params, {self.flow_layers} layers")
    
    def _get_parameter_bounds(self) -> Dict[str, Tuple[float, float]]:
        """Get reasonable parameter bounds for normalization."""
        bounds = {
            'mass_1': (5.0, 100.0),
            'mass_2': (5.0, 100.0),
            'luminosity_distance': (50.0, 3000.0),
            'geocent_time': (-0.1, 0.1),
            'ra': (0.0, 2*np.pi),
            'dec': (-np.pi/2, np.pi/2),
            'theta_jn': (0.0, np.pi),
            'psi': (0.0, np.pi),
            'phase': (0.0, 2*np.pi),
            'a_1': (0.0, 0.99),
            'a_2': (0.0, 0.99),
            'tilt_1': (0.0, np.pi),
            'tilt_2': (0.0, np.pi),
            'phi_12': (0.0, 2*np.pi),
            'phi_jl': (0.0, 2*np.pi)
        }
        return {param: bounds.get(param, (0.0, 1.0)) for param in self.param_names}
    
    def _build_context_encoder(self) -> nn.Module:
        """Build context encoder to process strain data."""
        return nn.Sequential(
            nn.Linear(self.context_features, 256),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, self.param_dim * 2)  # Mean and log-std for each parameter
        )
    
    def _normalize_parameters(self, params: torch.Tensor) -> torch.Tensor:
        """Normalize parameters to [0, 1] range."""
        normalized = torch.zeros_like(params)
        for i, param_name in enumerate(self.param_names):
            min_val, max_val = self.param_bounds[param_name]
            normalized[:, i] = (params[:, i] - min_val) / (max_val - min_val)
            normalized[:, i] = torch.clamp(normalized[:, i], 0.01, 0.99)  # Avoid boundaries
        return normalized
    
    def _denormalize_parameters(self, normalized_params: torch.Tensor) -> torch.Tensor:
        """Denormalize parameters back to physical range."""
        params = torch.zeros_like(normalized_params)
        for i, param_name in enumerate(self.param_names):
            min_val, max_val = self.param_bounds[param_name]
            params[:, i] = normalized_params[:, i] * (max_val - min_val) + min_val
        return params
    
    def _extract_context_features(self, data: Dict[str, np.ndarray]) -> torch.Tensor:
        """Extract context features from strain data."""
        try:
            features = []
            
            # Process each detector
            for det_name in ['H1', 'L1', 'V1']:
                if det_name in data:
                    strain = np.array(data[det_name])
                    if len(strain) > 0:
                        # Time domain features
                        features.extend([
                            np.mean(strain),
                            np.std(strain),
                            np.max(np.abs(strain)),
                            np.median(strain),
                            np.percentile(np.abs(strain), 95),
                            np.sqrt(np.mean(strain**2))  # RMS
                        ])
                        
                        # Simple frequency domain features
                        try:
                            fft_strain = np.fft.fft(strain)
                            power_spectrum = np.abs(fft_strain)**2
                            freqs = np.fft.fftfreq(len(strain), 1/4096)
                            
                            # Power in different frequency bands
                            low_freq_power = np.sum(power_spectrum[(freqs >= 20) & (freqs <= 100)])
                            mid_freq_power = np.sum(power_spectrum[(freqs >= 100) & (freqs <= 300)])
                            high_freq_power = np.sum(power_spectrum[(freqs >= 300) & (freqs <= 1000)])
                            
                            features.extend([
                                float(low_freq_power),
                                float(mid_freq_power),
                                float(high_freq_power),
                                float(np.argmax(power_spectrum[:len(freqs)//2]))  # Peak frequency index
                            ])
                        except:
                            features.extend([0.0, 0.0, 0.0, 0.0])
                    else:
                        features.extend([0.0] * 10)  # 6 time + 4 freq features
                else:
                    features.extend([0.0] * 10)
            
            # Cross-detector features
            try:
                if 'H1' in data and 'L1' in data:
                    h1_strain = np.array(data['H1'])
                    l1_strain = np.array(data['L1'])
                    
                    if len(h1_strain) == len(l1_strain) and len(h1_strain) > 0:
                        # Cross-correlation at zero lag
                        cross_corr = np.corrcoef(h1_strain, l1_strain)[0, 1]
                        features.append(float(cross_corr) if np.isfinite(cross_corr) else 0.0)
                        
                        # SNR estimate
                        h1_power = np.var(h1_strain)
                        l1_power = np.var(l1_strain)
                        network_power = h1_power + l1_power
                        features.append(float(np.sqrt(network_power * 1e46)))  # Rough SNR estimate
                    else:
                        features.extend([0.0, 10.0])
                else:
                    features.extend([0.0, 10.0])
            except:
                features.extend([0.0, 10.0])
            
            # Pad or truncate to expected size
            target_size = self.context_features
            if len(features) > target_size:
                features = features[:target_size]
            else:
                features.extend([0.0] * (target_size - len(features)))
            
            # Ensure all features are finite
            features = [f if np.isfinite(f) else 0.0 for f in features]
            
            return torch.tensor(features, dtype=torch.float32).unsqueeze(0)
            
        except Exception as e:
            self.logger.debug(f"Context feature extraction failed: {e}")
            return torch.zeros(1, self.context_features)
    
    def forward(self, parameters: torch.Tensor, context: torch.Tensor) -> torch.Tensor:
        """Forward pass through normalizing flow."""
        # Normalize parameters
        normalized_params = self._normalize_parameters(parameters)
        
        # Apply flow transformations
        x = normalized_params
        log_det_total = torch.zeros(x.shape[0])
        
        for layer in self.flow_layers_list:
            x, log_det = layer.forward(x, context)
            log_det_total += log_det
        
        # Base distribution log probability
        base_dist = MultivariateNormal(self.base_mean, self.base_cov)
        log_prob_base = base_dist.log_prob(x)
        
        # Total log probability
        log_prob = log_prob_base + log_det_total
        
        return log_prob
    
    def sample(self, context: torch.Tensor, num_samples: int = 1) -> torch.Tensor:
        """Sample from posterior given context."""
        try:
            # Sample from base distribution
            base_dist = MultivariateNormal(self.base_mean, self.base_cov)
            z = base_dist.sample((num_samples,))
            
            # Apply inverse transformations
            x = z
            for layer in reversed(self.flow_layers_list):
                x, _ = layer.inverse(x, context.repeat(num_samples, 1) if context.dim() == 2 else context)
            
            # Denormalize parameters
            samples = self._denormalize_parameters(x)
            
            return samples
            
        except Exception as e:
            self.logger.debug(f"Sampling failed: {e}")
            # Fallback: sample from prior
            samples = torch.zeros(num_samples, self.param_dim)
            for i, param_name in enumerate(self.param_names):
                min_val, max_val = self.param_bounds[param_name]
                samples[:, i] = torch.uniform(min_val, max_val, (num_samples,))
            return samples
    
    def quick_estimate(self, data: Dict[str, np.ndarray], detection_idx: int = 0) -> Dict:
        """Quick parameter estimation with uncertainty quantification."""
        
        try:
            # Extract context
            context = self._extract_context_features(data)
            
            # Generate posterior samples
            with torch.no_grad():
                num_samples = 100
                samples = self.sample(context, num_samples)
                
                # Compute posterior summary
                posterior_summary = {}
                for i, param_name in enumerate(self.param_names):
                    param_samples = samples[:, i].numpy()
                    
                    # Remove outliers (3-sigma clipping)
                    mean_val = np.mean(param_samples)
                    std_val = np.std(param_samples)
                    mask = np.abs(param_samples - mean_val) < 3 * std_val
                    clean_samples = param_samples[mask]
                    
                    if len(clean_samples) > 10:
                        posterior_summary[param_name] = {
                            'median': float(np.median(clean_samples)),
                            'mean': float(np.mean(clean_samples)),
                            'std': float(np.std(clean_samples)),
                            'quantiles': [
                                float(np.percentile(clean_samples, 5)),
                                float(np.percentile(clean_samples, 25)),
                                float(np.percentile(clean_samples, 50)),
                                float(np.percentile(clean_samples, 75)),
                                float(np.percentile(clean_samples, 95))
                            ]
                        }
                    else:
                        # Fallback for insufficient samples
                        min_val, max_val = self.param_bounds[param_name]
                        median_val = (min_val + max_val) / 2
                        posterior_summary[param_name] = {
                            'median': median_val,
                            'mean': median_val,
                            'std': (max_val - min_val) / 6,
                            'quantiles': [min_val, median_val*0.8, median_val, median_val*1.2, max_val]
                        }
                
                # Estimate signal quality based on context features
                context_norm = torch.norm(context).item()
                signal_quality = min(0.9, max(0.1, context_norm / 10.0))
                
                return {
                    'posterior_summary': posterior_summary,
                    'signal_quality': signal_quality,
                    'method': 'real_neural_pe',
                    'num_samples': num_samples
                }
                
        except Exception as e:
            self.logger.debug(f" Neural PE failed: {e}")
            return self._fallback_estimate()
    
    def _fallback_estimate(self) -> Dict:
        """Fallback parameter estimates."""
        posterior_summary = {}
        for param_name in self.param_names:
            min_val, max_val = self.param_bounds[param_name]
            
            if 'mass' in param_name:
                median = np.random.uniform(20, 50)
            elif 'distance' in param_name:
                median = np.random.uniform(200, 800)
            else:
                median = (min_val + max_val) / 2
            
            std = (max_val - min_val) / 6
            
            posterior_summary[param_name] = {
                'median': float(median),
                'mean': float(median),
                'std': float(std),
                'quantiles': [median - 2*std, median - std, median, median + std, median + 2*std]
            }
        
        return {
            'posterior_summary': posterior_summary,
            'signal_quality': 0.5,
            'method': 'fallback'
        }
    
    def set_complexity(self, complexity: str):
        """Set computational complexity."""
        complexity_map = {
            'low': 50,
            'medium': 100,
            'high': 200
        }
        self.num_samples = complexity_map.get(complexity, 100)
        self.logger.debug(f"Set Neural PE complexity to {complexity} ({self.num_samples} samples)")

# ============================================================================
# RL COMPLEXITY CONTROLLER
# ============================================================================

class AdaptiveComplexityController(nn.Module):
    """RL-based complexity controller for dynamic model adaptation"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__()
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # State features
        self.state_features = config.get('rl_controller', {}).get('state_features', [
            'current_loss', 'loss_trend', 'parameter_accuracy', 
            'signal_complexity', 'processing_efficiency', 'gradient_norm'
        ])
        self.state_dim = len(self.state_features)
        
        # Complexity levels
        self.complexity_levels = config.get('rl_controller', {}).get('complexity_levels', 
                                           ['minimal', 'standard', 'enhanced'])
        self.action_dim = len(self.complexity_levels)
        
        # Q-Network
        self.q_network = self._build_q_network()
        self.target_network = self._build_q_network()
        self.target_network.load_state_dict(self.q_network.state_dict())
        
        # RL parameters
        self.epsilon = config.get('rl_controller', {}).get('epsilon', 0.2)
        self.epsilon_decay = config.get('rl_controller', {}).get('epsilon_decay', 0.998)
        self.gamma = 0.95
        self.memory = deque(maxlen=config.get('rl_controller', {}).get('memory_size', 10000))
        
        # Optimizers
        self.optimizer = torch.optim.Adam(self.q_network.parameters(), 
                                        lr=config.get('rl_controller', {}).get('learning_rate', 1e-3))
        
        # State tracking
        self.current_state = torch.zeros(self.state_dim)
        self.previous_action = 1  # Start with standard complexity
        self.step_count = 0
        
    def _build_q_network(self) -> nn.Module:
        """Build Q-network for complexity selection"""
        return nn.Sequential(
            nn.Linear(self.state_dim, 128),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, self.action_dim)
        )
    
    def update_state(self, training_metrics: Dict[str, float]):
        """Update RL state based on training metrics"""
        state_vector = []
        
        for feature in self.state_features:
            if feature == 'current_loss':
                state_vector.append(training_metrics.get('loss', 1.0))
            elif feature == 'loss_trend':
                # Simple trend based on recent losses
                recent_losses = training_metrics.get('recent_losses', [1.0])
                if len(recent_losses) >= 2:
                    trend = recent_losses[-1] - recent_losses[-2]
                else:
                    trend = 0.0
                state_vector.append(trend)
            elif feature == 'parameter_accuracy':
                state_vector.append(training_metrics.get('param_accuracy', 0.5))
            elif feature == 'signal_complexity':
                state_vector.append(training_metrics.get('signal_complexity', 0.5))
            elif feature == 'processing_efficiency':
                state_vector.append(training_metrics.get('processing_time', 1.0))
            elif feature == 'gradient_norm':
                state_vector.append(training_metrics.get('gradient_norm', 1.0))
            else:
                state_vector.append(0.0)
        
        self.current_state = torch.tensor(state_vector, dtype=torch.float32)
    
    def select_complexity(self, training_mode: bool = True) -> str:
        """Select complexity level using epsilon-greedy policy"""
        if training_mode and random.random() < self.epsilon:
            # Exploration
            action = random.randint(0, self.action_dim - 1)
        else:
            # Exploitation
            with torch.no_grad():
                q_values = self.q_network(self.current_state.unsqueeze(0))
                action = q_values.argmax().item()
        
        self.previous_action = action
        return self.complexity_levels[action]
    
    def store_experience(self, state: torch.Tensor, action: int, reward: float, 
                        next_state: torch.Tensor, done: bool = False):
        """Store experience in replay buffer"""
        self.memory.append((state, action, reward, next_state, done))
    
    def compute_reward(self, prev_metrics: Dict, current_metrics: Dict, 
                      complexity_level: str) -> float:
        """Compute reward for RL training"""
        reward = 0.0
        
        # Accuracy improvement reward
        prev_acc = prev_metrics.get('param_accuracy', 0.5)
        curr_acc = current_metrics.get('param_accuracy', 0.5)
        accuracy_improvement = curr_acc - prev_acc
        reward += 2.0 * accuracy_improvement
        
        # Efficiency bonus (faster processing)
        prev_time = prev_metrics.get('processing_time', 1.0)
        curr_time = current_metrics.get('processing_time', 1.0)
        if curr_time < prev_time:
            reward += 0.5 * (prev_time - curr_time) / prev_time
        
        # Convergence bonus (stable loss)
        loss_stability = 1.0 / (1.0 + abs(current_metrics.get('loss_trend', 0.0)))
        reward += 1.0 * loss_stability
        
        # Complexity penalty (prefer simpler when possible)
        complexity_penalties = {'minimal': 0.0, 'standard': -0.1, 'enhanced': -0.2}
        reward += complexity_penalties.get(complexity_level, 0.0)
        
        return reward
    
    def train_rl_step(self) -> Optional[float]:
        """Train Q-network using experience replay"""
        if len(self.memory) < 64:
            return None
        
        batch = random.sample(self.memory, 64)
        states, actions, rewards, next_states, dones = zip(*batch)
        
        states = torch.stack(states)
        actions = torch.tensor(actions, dtype=torch.long)
        rewards = torch.tensor(rewards, dtype=torch.float32)
        next_states = torch.stack(next_states)
        dones = torch.tensor(dones, dtype=torch.bool)
        
        # Current Q values
        current_q_values = self.q_network(states).gather(1, actions.unsqueeze(1))
        
        # Next Q values from target network
        with torch.no_grad():
            next_q_values = self.target_network(next_states).max(1)[0]
            target_q_values = rewards + (self.gamma * next_q_values * ~dones)
        
        # Compute loss
        loss = F.mse_loss(current_q_values.squeeze(), target_q_values)
        
        # Optimize
        self.optimizer.zero_grad()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(self.q_network.parameters(), 1.0)
        self.optimizer.step()
        
        # Update epsilon
        self.epsilon = max(0.01, self.epsilon * self.epsilon_decay)
        
        return loss.item()
    
    def update_target_network(self):
        """Update target network"""
        self.target_network.load_state_dict(self.q_network.state_dict())

# ============================================================================
# ADAPTIVE NORMALIZING FLOWS
# ============================================================================

class AdaptiveRealNVP(nn.Module):
    """Adaptive Real NVP with RL-controlled depth"""
    
    def __init__(self, features: int, context_features: int = 0, 
                 max_layers: int = 12, hidden_features: int = 128):
        super().__init__()
        self.features = features
        self.context_features = context_features
        self.max_layers = max_layers
        self.hidden_features = hidden_features
        
        # Build all possible layers
        self.coupling_layers = nn.ModuleList()
        for i in range(max_layers):
            mask = self._create_mask(features, i % 2 == 0)
            layer = CouplingLayer(features, hidden_features, context_features, mask)
            self.coupling_layers.append(layer)
        
        # Active layers (controlled by RL)
        self._active_layers = 8  # Default
        
    def _create_mask(self, features: int, even: bool) -> torch.Tensor:
        """Create alternating mask for coupling layers"""
        mask = torch.zeros(features)
        if even:
            mask[::2] = 1
        else:
            mask[1::2] = 1
        return mask
    
    @property
    def active_layers(self) -> int:
        return self._active_layers
    
    @active_layers.setter
    def active_layers(self, value: int):
        self._active_layers = min(max(1, value), self.max_layers)
    
    def forward(self, x: torch.Tensor, context: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]:
        """Forward pass through active layers"""
        log_det = torch.zeros(x.size(0), device=x.device)
        
        for i in range(self.active_layers):
            x, ld = self.coupling_layers[i](x, context)
            log_det += ld
            
        return x, log_det
    
    def inverse(self, z: torch.Tensor, context: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]:
        """Inverse pass through active layers"""
        log_det = torch.zeros(z.size(0), device=z.device)
        
        for i in reversed(range(self.active_layers)):
            z, ld = self.coupling_layers[i].inverse(z, context)
            log_det += ld
            
        return z, log_det

class CouplingLayer(nn.Module):
    """Coupling layer for Real NVP"""
    
    def __init__(self, features: int, hidden_features: int, context_features: int, mask: torch.Tensor):
        super().__init__()
        self.register_buffer('mask', mask)
        
        # Scale and translation networks
        input_dim = int(mask.sum().item()) + context_features
        
        self.scale_net = nn.Sequential(
            nn.Linear(input_dim, hidden_features),
            nn.ReLU(),
            nn.Linear(hidden_features, hidden_features),
            nn.ReLU(),
            nn.Linear(hidden_features, features - int(mask.sum().item())),
            nn.Tanh()  # Bounded for stability
        )
        
        self.translate_net = nn.Sequential(
            nn.Linear(input_dim, hidden_features),
            nn.ReLU(),
            nn.Linear(hidden_features, hidden_features),
            nn.ReLU(),
            nn.Linear(hidden_features, features - int(mask.sum().item()))
        )
    
    def forward(self, x: torch.Tensor, context: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]:
        """Forward coupling transformation"""
        x_masked = x * self.mask
        
        # Prepare input for networks
        if context is not None:
            net_input = torch.cat([x_masked, context], dim=1)
        else:
            net_input = x_masked
        
        # Compute scale and translation
        s = self.scale_net(net_input)
        t = self.translate_net(net_input)
        
        # Apply transformation
        x_new = x_masked + (1 - self.mask) * (x * torch.exp(s) + t)
        log_det = ((1 - self.mask) * s).sum(dim=1)
        
        return x_new, log_det
    
    def inverse(self, y: torch.Tensor, context: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]:
        """Inverse coupling transformation"""
        y_masked = y * self.mask
        
        # Prepare input for networks
        if context is not None:
            net_input = torch.cat([y_masked, context], dim=1)
        else:
            net_input = y_masked
        
        # Compute scale and translation
        s = self.scale_net(net_input)
        t = self.translate_net(net_input)
        
        # Apply inverse transformation
        x_new = y_masked + (1 - self.mask) * (y - t) * torch.exp(-s)
        log_det = -((1 - self.mask) * s).sum(dim=1)
        
        return x_new, log_det

# ============================================================================
# BIAS CORRECTOR
# ============================================================================

class HierarchicalBiasCorrector(nn.Module):
    """Hierarchical bias correction with physics constraints"""
    
    def __init__(self, param_names: List[str], config: Dict[str, Any]):
        super().__init__()
        self.param_names = param_names
        self.param_dim = len(param_names)
        self.config = config
        
        # Parameter hierarchies
        self.primary_params = ['mass_1', 'mass_2', 'luminosity_distance']
        self.secondary_params = ['theta_jn', 'phi_jl', 'ra', 'dec']
        self.tertiary_params = ['tilt_1', 'tilt_2', 'phi_12', 'a_1', 'a_2']
        
        # Bias correction networks for each hierarchy
        self.primary_corrector = self._build_corrector_network(len(self.primary_params))
        self.secondary_corrector = self._build_corrector_network(len(self.secondary_params))
        self.tertiary_corrector = self._build_corrector_network(len(self.tertiary_params))
        
        # Physics constraint networks
        self.constraint_net = self._build_constraint_network()
        
        # Confidence estimator
        self.confidence_estimator = self._build_confidence_network()
        
    def _build_corrector_network(self, output_dim: int) -> nn.Module:
        """Build bias correction network"""
        return nn.Sequential(
            nn.Linear(self.param_dim + 16, 256),  # params + context features
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, output_dim * 2)  # mean and log_std for each param
        )
    
    def _build_constraint_network(self) -> nn.Module:
        """Build physics constraint network"""
        return nn.Sequential(
            nn.Linear(self.param_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Sigmoid()  # Constraint satisfaction probability
        )
    
    def _build_confidence_network(self) -> nn.Module:
        """Build confidence estimation network"""
        return nn.Sequential(
            nn.Linear(self.param_dim + 16, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()  # Confidence score
        )
    
    def forward(self, parameters: torch.Tensor, context: torch.Tensor, 
                uncertainties: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """Apply hierarchical bias correction"""
        batch_size = parameters.size(0)
        
        # Extract parameter subsets
        primary_indices = [self.param_names.index(p) for p in self.primary_params if p in self.param_names]
        secondary_indices = [self.param_names.index(p) for p in self.secondary_params if p in self.param_names]
        tertiary_indices = [self.param_names.index(p) for p in self.tertiary_params if p in self.param_names]
        
        # Prepare input
        correction_input = torch.cat([parameters, context], dim=1)
        
        # Apply hierarchical corrections
        corrections = torch.zeros_like(parameters)
        correction_uncertainties = torch.zeros_like(parameters)
        
        if primary_indices:
            primary_output = self.primary_corrector(correction_input)
            primary_corrections = primary_output[:, :len(primary_indices)]
            primary_log_stds = primary_output[:, len(primary_indices):]
            
            corrections[:, primary_indices] = primary_corrections
            correction_uncertainties[:, primary_indices] = torch.exp(primary_log_stds)
        
        if secondary_indices:
            secondary_output = self.secondary_corrector(correction_input)
            secondary_corrections = secondary_output[:, :len(secondary_indices)]
            secondary_log_stds = secondary_output[:, len(secondary_indices):]
            
            corrections[:, secondary_indices] = secondary_corrections
            correction_uncertainties[:, secondary_indices] = torch.exp(secondary_log_stds)
        
        if tertiary_indices:
            tertiary_output = self.tertiary_corrector(correction_input)
            tertiary_corrections = tertiary_output[:, :len(tertiary_indices)]
            tertiary_log_stds = tertiary_output[:, len(tertiary_indices):]
            
            corrections[:, tertiary_indices] = tertiary_corrections
            correction_uncertainties[:, tertiary_indices] = torch.exp(tertiary_log_stds)
        
        # Apply physics constraints
        constraint_satisfaction = self.constraint_net(parameters + corrections)
        
        # Scale corrections by constraint satisfaction
        corrections = corrections * constraint_satisfaction
        
        # Compute confidence
        confidence = self.confidence_estimator(correction_input)
        
        return corrections, correction_uncertainties, confidence

# ============================================================================
# MULTI-SCALE CONTEXT ENCODER
# ============================================================================

class MultiScaleContextEncoder(nn.Module):
    """Multi-scale context encoder for waveform data"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__()
        self.config = config
        
        # Multi-scale convolutional paths
        self.short_scale_path = self._build_conv_path(kernel_size=8, out_channels=32)
        self.medium_scale_path = self._build_conv_path(kernel_size=16, out_channels=64)
        self.long_scale_path = self._build_conv_path(kernel_size=32, out_channels=128)
        
        # Feature fusion
        self.fusion_net = nn.Sequential(
            nn.Linear(32 + 64 + 128, 512),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Linear(256, config.get('neural_pe', {}).get('context_features', 512))
        )
        
        # Attention mechanism
        self.attention = nn.MultiheadAttention(embed_dim=256, num_heads=8, batch_first=True)
        
    def _build_conv_path(self, kernel_size: int, out_channels: int) -> nn.Module:
        """Build convolutional path for specific scale"""
        return nn.Sequential(
            nn.Conv1d(2, out_channels, kernel_size=kernel_size, padding=kernel_size//2),
            nn.BatchNorm1d(out_channels),
            nn.ReLU(),
            nn.AdaptiveMaxPool1d(16),
            nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm1d(out_channels),
            nn.ReLU(),
            nn.AdaptiveAvgPool1d(1),
            nn.Flatten()
        )
    
    def forward(self, waveform_data: torch.Tensor) -> torch.Tensor:
        """Extract multi-scale context features"""
        # Extract features at different scales
        short_features = self.short_scale_path(waveform_data)
        medium_features = self.medium_scale_path(waveform_data)
        long_features = self.long_scale_path(waveform_data)
        
        # Concatenate features
        combined_features = torch.cat([short_features, medium_features, long_features], dim=1)
        
        # Fuse features
        context_features = self.fusion_net(combined_features)
        
        return context_features

# ============================================================================
# BEST-IN-CLASS NEURAL PE
# ============================================================================

class BestInClassNeuralPE(nn.Module):
    """Best-in-class Neural Posterior Estimator with all advanced features"""
    
    def __init__(self, param_names: List[str], config: Dict[str, Any]):
        super().__init__()
        
        self.param_names = param_names
        self.param_dim = len(param_names)
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # Parameter bounds for normalization
        self.param_bounds = self._get_parameter_bounds()
        
        # RL complexity controller
        self.rl_controller = AdaptiveComplexityController(config)
        self.current_complexity = 'standard'
        
        # Multi-scale context encoder
        self.context_encoder = MultiScaleContextEncoder(config)
        context_dim = config.get('neural_pe', {}).get('context_features', 512)
        
        # Adaptive normalizing flow
        flow_config = config.get('neural_pe', {}).get('flow_config', {})
        max_layers = flow_config.get('num_layers', 12)
        hidden_features = flow_config.get('hidden_features', 128)
        
        self.flow_model = AdaptiveRealNVP(
            features=self.param_dim,
            context_features=context_dim,
            max_layers=max_layers,
            hidden_features=hidden_features
        )
        
        # Hierarchical bias corrector
        self.bias_corrector = HierarchicalBiasCorrector(param_names, config)
        
        # Uncertainty estimator
        self.uncertainty_estimator = nn.Sequential(
            nn.Linear(self.param_dim + context_dim, 256),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, self.param_dim),
            nn.Softplus()  # Ensure positive uncertainties
        )
        
        # Physics-informed priors
        self.physics_priors = self._build_physics_priors()
        
        # Performance tracking
        self.performance_tracker = {
            'training_losses': deque(maxlen=1000),
            'validation_metrics': deque(maxlen=100),
            'complexity_history': deque(maxlen=1000),
            'inference_times': deque(maxlen=1000),
            'rl_rewards': deque(maxlen=1000)
        }
        
        # Training state
        self.training_step = 0
        self.last_rl_update = 0
        
    def _get_parameter_bounds(self) -> Dict[str, Tuple[float, float]]:
        """Get parameter bounds for normalization"""
        bounds = {
            'mass_1': (1.0, 100.0),
            'mass_2': (1.0, 100.0),
            'luminosity_distance': (20.0, 8000.0),
            'geocent_time': (-0.1, 0.1),
            'ra': (0.0, 2*np.pi),
            'dec': (-np.pi/2, np.pi/2),
            'theta_jn': (0.0, np.pi),
            'psi': (0.0, np.pi),
            'phase': (0.0, 2*np.pi),
            'a_1': (0.0, 0.99),
            'a_2': (0.0, 0.99),
            'tilt_1': (0.0, np.pi),
            'tilt_2': (0.0, np.pi),
            'phi_12': (0.0, 2*np.pi),
            'phi_jl': (0.0, 2*np.pi)
        }
        return {param: bounds.get(param, (0.0, 1.0)) for param in self.param_names}
    
    def _build_physics_priors(self) -> Dict[str, torch.distributions.Distribution]:
        """Build physics-informed priors"""
        priors = {}
        
        for param in self.param_names:
            if 'mass' in param:
                # Power-law priors for masses
                priors[param] = torch.distributions.Pareto(1.0, 2.35)  # Salpeter IMF
            elif param in ['ra', 'phase', 'phi_12', 'phi_jl']:
                # Uniform priors for angles
                priors[param] = torch.distributions.Uniform(0.0, 2*np.pi)
            elif param in ['dec', 'theta_jn', 'tilt_1', 'tilt_2']:
                # Sine priors for spherical angles
                priors[param] = torch.distributions.Beta(0.5, 0.5)
            elif param == 'luminosity_distance':
                # Volume prior for distance
                priors[param] = torch.distributions.Pareto(1.0, 2.0)
            else:
                # Default uniform prior
                priors[param] = torch.distributions.Uniform(0.0, 1.0)
        
        return priors
    
    def _normalize_parameters(self, params: torch.Tensor) -> torch.Tensor:
        """Normalize parameters to [-1, 1]"""
        normalized = torch.zeros_like(params)
        
        for i, param_name in enumerate(self.param_names):
            min_val, max_val = self.param_bounds[param_name]
            normalized[:, i] = 2 * (params[:, i] - min_val) / (max_val - min_val) - 1
            
        return torch.clamp(normalized, -1, 1)
    
    def _denormalize_parameters(self, normalized_params: torch.Tensor) -> torch.Tensor:
        """Denormalize parameters from [-1, 1]"""
        params = torch.zeros_like(normalized_params)
        
        for i, param_name in enumerate(self.param_names):
            min_val, max_val = self.param_bounds[param_name]
            params[:, i] = (normalized_params[:, i] + 1) / 2 * (max_val - min_val) + min_val
            
        return params
    
    def _update_complexity_from_rl(self, training_metrics: Dict[str, float]):
        """Update model complexity based on RL controller"""
        # Update RL state
        self.rl_controller.update_state(training_metrics)
        
        # Select new complexity
        new_complexity = self.rl_controller.select_complexity(self.training)
        
        if new_complexity != self.current_complexity:
            self.logger.info(f"RL Controller: Switching complexity from {self.current_complexity} to {new_complexity}")
            
            # Update flow model complexity
            complexity_configs = self.config.get('rl_controller', {}).get('complexity_configs', {})
            complexity_config = complexity_configs.get(new_complexity, complexity_configs.get('standard', {}))
            
            new_layers = complexity_config.get('flow_layers', 8)
            self.flow_model.active_layers = new_layers
            
            self.current_complexity = new_complexity
            self.performance_tracker['complexity_history'].append(new_complexity)
    
    def forward(self, waveform_data: torch.Tensor, target_params: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:
        """Forward pass with all components"""
        batch_size = waveform_data.size(0)
        
        # Extract context features
        context = self.context_encoder(waveform_data)
        
        if target_params is not None:
            # Training mode: compute loss
            normalized_params = self._normalize_parameters(target_params)
            
            # Forward through flow
            z, log_det = self.flow_model(normalized_params, context)
            
            # Compute log probability
            prior_log_prob = -0.5 * torch.sum(z**2, dim=1) - 0.5 * self.param_dim * np.log(2 * np.pi)
            log_prob = prior_log_prob + log_det
            
            # Apply bias correction
            corrections, correction_uncertainties, confidence = self.bias_corrector(
                normalized_params, context
            )
            corrected_params = normalized_params + corrections
            
            # Estimate uncertainties
            uncertainties = self.uncertainty_estimator(
                torch.cat([normalized_params, context], dim=1)
            )
            
            return {
                'log_prob': log_prob,
                'corrections': corrections,
                'correction_uncertainties': correction_uncertainties,
                'uncertainties': uncertainties,
                'confidence': confidence,
                'context': context
            }
        else:
            # Inference mode: sample from posterior
            return self._sample_posterior(context, num_samples=1000)
    
    def _sample_posterior(self, context: torch.Tensor, num_samples: int = 1000) -> Dict[str, torch.Tensor]:
        """Sample from posterior distribution"""
        batch_size = context.size(0)
        
        # Sample from prior
        z = torch.randn(batch_size, num_samples, self.param_dim, device=context.device)
        
        # Transform through flow
        samples_list = []
        for i in range(batch_size):
            context_i = context[i:i+1].expand(num_samples, -1)
            z_i = z[i]
            
            # Inverse flow transformation
            samples_i, _ = self.flow_model.inverse(z_i, context_i)
            
            # Apply bias correction
            corrections, _, confidence = self.bias_corrector(samples_i, context_i)
            corrected_samples = samples_i + corrections
            
            # Denormalize
            physical_samples = self._denormalize_parameters(corrected_samples)
            samples_list.append(physical_samples)
        
        samples = torch.stack(samples_list, dim=0)
        
        # Compute summary statistics
        means = samples.mean(dim=1)
        stds = samples.std(dim=1)
        
        # Compute uncertainties
        uncertainties = self.uncertainty_estimator(
            torch.cat([self._normalize_parameters(means), context], dim=1)
        )
        
        return {
            'samples': samples,
            'means': means,
            'stds': stds,
            'uncertainties': uncertainties,
            'context': context
        }
    
    def compute_loss(self, waveform_data: torch.Tensor, target_params: torch.Tensor) -> Dict[str, torch.Tensor]:
        """Compute comprehensive training loss"""
        forward_output = self.forward(waveform_data, target_params)
        
        # Flow loss (negative log likelihood)
        flow_loss = -forward_output['log_prob'].mean()
        
        # Bias correction loss
        corrections = forward_output['corrections']
        correction_uncertainties = forward_output['correction_uncertainties']
        
        # L2 regularization on corrections (prefer small corrections)
        correction_loss = 0.1 * torch.mean(corrections**2)
        
        # Uncertainty loss (encourage calibrated uncertainties)
        uncertainties = forward_output['uncertainties']
        uncertainty_loss = 0.01 * torch.mean(uncertainties)
        
        # Physics constraint loss
        normalized_params = self._normalize_parameters(target_params)
        corrected_params = normalized_params + corrections
        physical_params = self._denormalize_parameters(corrected_params)
        
        physics_loss = self._compute_physics_loss(physical_params)
        
        # Total loss
        total_loss = flow_loss + correction_loss + uncertainty_loss + physics_loss
        
        return {
            'total_loss': total_loss,
            'flow_loss': flow_loss,
            'correction_loss': correction_loss,
            'uncertainty_loss': uncertainty_loss,
            'physics_loss': physics_loss,
            'confidence': forward_output['confidence'].mean()
        }
    
    def _compute_physics_loss(self, params: torch.Tensor) -> torch.Tensor:
        """Compute physics constraint loss"""
        loss = torch.tensor(0.0, device=params.device)
        
        # Mass ordering constraint
        if 'mass_1' in self.param_names and 'mass_2' in self.param_names:
            m1_idx = self.param_names.index('mass_1')
            m2_idx = self.param_names.index('mass_2')
            
            # Penalize m2 > m1
            mass_violation = F.relu(params[:, m2_idx] - params[:, m1_idx])
            loss += torch.mean(mass_violation**2)
        
        # Spin magnitude constraints
        for param in ['a_1', 'a_2']:
            if param in self.param_names:
                idx = self.param_names.index(param)
                # Penalize |a| > 1
                spin_violation = F.relu(params[:, idx] - 0.99)
                loss += torch.mean(spin_violation**2)
        
        return loss
    
    def update_training_metrics(self, loss_dict: Dict[str, torch.Tensor], 
                              processing_time: float, gradient_norm: float):
        """Update training metrics for RL controller"""
        self.training_step += 1
        
        # Store metrics
        self.performance_tracker['training_losses'].append(loss_dict['total_loss'].item())
        self.performance_tracker['inference_times'].append(processing_time)
        
        # Update RL controller every N steps
        if self.training_step % 200 == 0:
            recent_losses = list(self.performance_tracker['training_losses'])[-10:]
            
            training_metrics = {
                'loss': loss_dict['total_loss'].item(),
                'recent_losses': recent_losses,
                'param_accuracy': 1.0 / (1.0 + loss_dict['flow_loss'].item()),  # Rough accuracy metric
                'signal_complexity': 0.5,  # Would be computed from data
                'processing_time': processing_time,
                'gradient_norm': gradient_norm
            }
            
            # Store previous metrics for reward computation
            if hasattr(self, 'previous_metrics'):
                reward = self.rl_controller.compute_reward(
                    self.previous_metrics, training_metrics, self.current_complexity
                )
                self.performance_tracker['rl_rewards'].append(reward)
                
                # Store experience
                self.rl_controller.store_experience(
                    self.rl_controller.current_state,
                    self.rl_controller.previous_action,
                    reward,
                    self.rl_controller.current_state  # Would be updated state
                )
            
            # Update complexity
            self._update_complexity_from_rl(training_metrics)
            self.previous_metrics = training_metrics
            
            # Train RL controller
            if len(self.rl_controller.memory) > 64:
                rl_loss = self.rl_controller.train_rl_step()
                if rl_loss is not None:
                    self.logger.debug(f"RL Controller loss: {rl_loss:.4f}")
        
        # Update target network periodically
        if self.training_step % 1000 == 0:
            self.rl_controller.update_target_network()
    
    def quick_estimate(self, data: Dict[str, np.ndarray], detection_idx: int = 0) -> Dict:
        """Quick parameter estimation for real-time processing"""
        start_time = time.time()
        
        try:
            # Convert to tensor
            if isinstance(data, dict) and 'H1' in data:
                # Multi-detector data
                h1_data = torch.tensor(data['H1'], dtype=torch.float32).unsqueeze(0)
                if 'L1' in data:
                    l1_data = torch.tensor(data['L1'], dtype=torch.float32).unsqueeze(0)
                    waveform_data = torch.stack([h1_data.squeeze(), l1_data.squeeze()], dim=0).unsqueeze(0)
                else:
                    # Duplicate H1 for L1
                    waveform_data = torch.stack([h1_data.squeeze(), h1_data.squeeze()], dim=0).unsqueeze(0)
            else:
                # Single detector or array data
                if isinstance(data, dict):
                    data_array = list(data.values())[0]
                else:
                    data_array = data
                
                data_tensor = torch.tensor(data_array, dtype=torch.float32)
                if data_tensor.dim() == 1:
                    # Duplicate for two detectors
                    waveform_data = data_tensor.unsqueeze(0).repeat(1, 2, 1)
                else:
                    waveform_data = data_tensor.unsqueeze(0)
            
            # Ensure correct shape [batch, detectors, samples]
            if waveform_data.dim() == 2:
                waveform_data = waveform_data.unsqueeze(0)
            
            # Set to minimal complexity for speed
            original_complexity = self.current_complexity
            self.current_complexity = 'minimal'
            self.flow_model.active_layers = 4
            
            # Forward pass
            with torch.no_grad():
                result = self._sample_posterior(
                    self.context_encoder(waveform_data),
                    num_samples=100  # Fewer samples for speed
                )
            
            # Restore original complexity
            self.current_complexity = original_complexity
            
            # Convert to numpy and create output
            means = result['means'].squeeze().numpy()
            stds = result['stds'].squeeze().numpy()
            uncertainties = result['uncertainties'].squeeze().numpy()
            
            # Create parameter estimates
            estimates = {}
            quantiles = {}
            
            for i, param_name in enumerate(self.param_names):
                estimates[param_name] = float(means[i])
                
                # Compute credible intervals
                std = stds[i]
                quantiles[param_name] = [
                    float(means[i] - 2*std),  # 2.5%
                    float(means[i] - std),    # 16%
                    float(means[i]),          # 50%
                    float(means[i] + std),    # 84%
                    float(means[i] + 2*std)   # 97.5%
                ]
            
            processing_time = time.time() - start_time
            
            return {
                'parameter_estimates': estimates,
                'quantiles': quantiles,
                'uncertainties': {param: float(uncertainties[i]) for i, param in enumerate(self.param_names)},
                'signal_quality': float(torch.mean(result['uncertainties']).item()),
                'processing_time': processing_time,
                'method': 'BestInClassNeuralPE',
                'complexity': self.current_complexity,
                'samples_used': 100
            }
            
        except Exception as e:
            self.logger.error(f"Quick estimation failed: {e}")
            return self._fallback_estimate()
    
    def _fallback_estimate(self) -> Dict:
        """Fallback parameter estimation"""
        estimates = {}
        quantiles = {}
        uncertainties = {}
        
        # Default parameter values
        defaults = {
            'mass_1': 30.0, 'mass_2': 25.0, 'luminosity_distance': 400.0,
            'geocent_time': 0.0, 'ra': np.pi, 'dec': 0.0,
            'theta_jn': np.pi/2, 'psi': 0.0, 'phase': 0.0,
            'a_1': 0.0, 'a_2': 0.0, 'tilt_1': 0.0, 'tilt_2': 0.0,
            'phi_12': 0.0, 'phi_jl': 0.0
        }
        
        for param_name in self.param_names:
            default_val = defaults.get(param_name, 0.5)
            estimates[param_name] = default_val
            uncertainties[param_name] = abs(default_val * 0.5)
            
            # Wide quantiles for fallback
            quantiles[param_name] = [
                default_val * 0.5, default_val * 0.75, default_val,
                default_val * 1.25, default_val * 1.5
            ]
        
        return {
            'parameter_estimates': estimates,
            'quantiles': quantiles,
            'uncertainties': uncertainties,
            'signal_quality': 0.1,
            'processing_time': 0.001,
            'method': 'fallback',
            'complexity': 'minimal',
            'samples_used': 0
        }
    
    def save_model(self, filepath: str):
        """Save complete model state"""
        state_dict = {
            'model_state_dict': self.state_dict(),
            'param_names': self.param_names,
            'param_bounds': self.param_bounds,
            'config': self.config,
            'current_complexity': self.current_complexity,
            'training_step': self.training_step,
            'performance_tracker': {
                k: list(v) for k, v in self.performance_tracker.items()
            }
        }
        torch.save(state_dict, filepath)
        self.logger.info(f"Model saved to {filepath}")
    
    def load_model(self, filepath: str):
        """Load complete model state"""
        checkpoint = torch.load(filepath, map_location='cpu')
        
        self.load_state_dict(checkpoint['model_state_dict'])
        self.current_complexity = checkpoint.get('current_complexity', 'standard')
        self.training_step = checkpoint.get('training_step', 0)
        
        # Restore performance tracker
        if 'performance_tracker' in checkpoint:
            for k, v in checkpoint['performance_tracker'].items():
                self.performance_tracker[k] = deque(v, maxlen=self.performance_tracker[k].maxlen)
        
        self.logger.info(f"Model loaded from {filepath}")
    
    def get_model_summary(self) -> Dict[str, Any]:
        """Get comprehensive model summary"""
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        
        return {
            'model_type': 'BestInClassNeuralPE',
            'parameter_names': self.param_names,
            'parameter_dimension': self.param_dim,
            'total_parameters': total_params,
            'trainable_parameters': trainable_params,
            'current_complexity': self.current_complexity,
            'active_flow_layers': self.flow_model.active_layers,
            'training_step': self.training_step,
            'recent_performance': {
                'avg_loss': np.mean(list(self.performance_tracker['training_losses'])[-10:]) if self.performance_tracker['training_losses'] else 0.0,
                'avg_inference_time': np.mean(list(self.performance_tracker['inference_times'])[-10:]) if self.performance_tracker['inference_times'] else 0.0,
                'complexity_distribution': {
                    complexity: list(self.performance_tracker['complexity_history']).count(complexity)
                    for complexity in ['minimal', 'standard', 'enhanced']
                }
            }
        }

# Backward compatibility alias
NeuralPE = BestInClassNeuralPE
